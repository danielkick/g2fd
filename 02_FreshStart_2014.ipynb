{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce112a12",
   "metadata": {},
   "source": [
    "# Process Data from 2014 into a consistent format.\n",
    "\n",
    "> This notebook brings the 2014 into alignment with the desired format with respect to field name, type, and grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9bf5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports ----\n",
    "import re\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf3e182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from g2fd.internal import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569c88f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp internal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1692f5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2014\n",
    "year_string = '2014'\n",
    "\n",
    "meta_path = './data/raw/G2F_Planting_Season_2014_v4/z._2014_supplemental_info/g2f_2014_field_characteristics.csv' \n",
    "phno_path = './data/raw/G2F_Planting_Season_2014_v4/a._2014_hybrid_phenotypic_data/g2f_2014_hybrid_data_clean.csv' \n",
    "# geno_path = None,  \n",
    "wthr_path = './data/raw/G2F_Planting_Season_2014_v4/b._2014_weather_data/g2f_2014_weather.csv'\n",
    "          # no soil 2014, some info in metadata\n",
    "# soil_path = None, \n",
    "          # no agro 2014, some info in metadata\n",
    "# mgmt_path = None,\n",
    "\n",
    "meta = pd.read_csv(meta_path, encoding = \"ISO-8859-1\", low_memory=False)\n",
    "phno = pd.read_csv(phno_path, encoding = \"ISO-8859-1\", low_memory=False)\n",
    "wthr = pd.read_csv(wthr_path, encoding = \"ISO-8859-1\", low_memory=False)\n",
    "# soil = pd.read_csv(soil_path, encoding = \"ISO-8859-1\", low_memory=False)\n",
    "# mgmt = pd.read_csv(mgmt_path, encoding = \"ISO-8859-1\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d31cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dicts for column renaming\n",
    "meta_name_dict = mk_name_dict(name = 'meta')\n",
    "phno_name_dict = mk_name_dict(name = 'phno')\n",
    "wthr_name_dict = mk_name_dict(name = 'wthr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1ab577",
   "metadata": {},
   "source": [
    "# Rename\n",
    "**Naming rules:**\n",
    "- One dict for each input df\n",
    "- Comment out anything that shouldn't be changed\n",
    "- Upper_Upper_Unit_\\$unit\n",
    "- Upper_$number\n",
    "- No special characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0b0a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [], [])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(find_unrecognized_columns(df = meta, dct = meta_name_dict),\n",
    "find_unrecognized_columns(df = phno, dct = phno_name_dict),\n",
    "find_unrecognized_columns(df = wthr, dct = wthr_name_dict)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9080f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = meta.rename(columns=meta_name_dict)\n",
    "phno = phno.rename(columns=phno_name_dict)\n",
    "wthr = wthr.rename(columns=wthr_name_dict)\n",
    "\n",
    "# add indicator columns to help with debugging merge\n",
    "meta['meta'] = True\n",
    "phno['phno'] = True\n",
    "wthr['wthr'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23a57b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.loc[meta.Experiment_Code.isna(), 'Experiment_Code'] = meta.loc[meta.Experiment_Code.isna(), 'Location_Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485b4fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(42, 43), (12675, 39), (207004, 25)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e.shape for e in [meta, phno, wthr]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1589ac0",
   "metadata": {},
   "source": [
    "# Sanatize ID columns as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce87912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location_Name</th>\n",
       "      <th>Type</th>\n",
       "      <th>Experiment_Code</th>\n",
       "      <th>City</th>\n",
       "      <th>Farm</th>\n",
       "      <th>Field</th>\n",
       "      <th>Field_Longitude_BL</th>\n",
       "      <th>Field_Latitude_BL</th>\n",
       "      <th>Plot_Length_Unit_Feet</th>\n",
       "      <th>Alley_Length_Unit_Inches</th>\n",
       "      <th>Row_Spacing_Unit_Inches</th>\n",
       "      <th>Kernels_Per_Plot</th>\n",
       "      <th>Planter_Type</th>\n",
       "      <th>Previous_Crop</th>\n",
       "      <th>Insecticide</th>\n",
       "      <th>Pre_Plant_Herbicide</th>\n",
       "      <th>Post_Plant_Herbicide</th>\n",
       "      <th>Tillage</th>\n",
       "      <th>Soil_Test</th>\n",
       "      <th>Texture</th>\n",
       "      <th>Soil_1_to_1_Unit_pH</th>\n",
       "      <th>N_Unit_lbs_per_A</th>\n",
       "      <th>P_Unit_lbs_per_A</th>\n",
       "      <th>K_Unit_lbs_per_A</th>\n",
       "      <th>Nutrient_Schedule</th>\n",
       "      <th>Irrigation_Applied</th>\n",
       "      <th>Weather_Station_Documents_Irrigation</th>\n",
       "      <th>Fertigation_Schedule</th>\n",
       "      <th>Irrigation_Schedule</th>\n",
       "      <th>Local_Check</th>\n",
       "      <th>Harvested_Unit_Datetime</th>\n",
       "      <th>Planted_Unit_Datetime</th>\n",
       "      <th>Inbred_Reps</th>\n",
       "      <th>Inbred_Plots</th>\n",
       "      <th>Collaborator</th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Traits_Measured</th>\n",
       "      <th>Folder_Name</th>\n",
       "      <th>Metadata_File</th>\n",
       "      <th>Additional_Metadata</th>\n",
       "      <th>Weather_Station_In_Field_Serial_Number</th>\n",
       "      <th>Weather_Directory</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Location_Name, Type, Experiment_Code, City, Farm, Field, Field_Longitude_BL, Field_Latitude_BL, Plot_Length_Unit_Feet, Alley_Length_Unit_Inches, Row_Spacing_Unit_Inches, Kernels_Per_Plot, Planter_Type, Previous_Crop, Insecticide, Pre_Plant_Herbicide, Post_Plant_Herbicide, Tillage, Soil_Test, Texture, Soil_1_to_1_Unit_pH, N_Unit_lbs_per_A, P_Unit_lbs_per_A, K_Unit_lbs_per_A, Nutrient_Schedule, Irrigation_Applied, Weather_Station_Documents_Irrigation, Fertigation_Schedule, Irrigation_Schedule, Local_Check, Harvested_Unit_Datetime, Planted_Unit_Datetime, Inbred_Reps, Inbred_Plots, Collaborator, File_Name, Traits_Measured, Folder_Name, Metadata_File, Additional_Metadata, Weather_Station_In_Field_Serial_Number, Weather_Directory, meta]\n",
       "Index: []"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix missing value\n",
    "mask = meta.Experiment_Code.isna()\n",
    "meta.loc[mask, :]# 'Experiment_Code'] = meta.loc[mask, 'State']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca242c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wthr = sanitize_Experiment_Codes(\n",
    "    df = wthr, \n",
    "    simple_renames = {\n",
    "    }, \n",
    "    split_renames = {\n",
    "        'IAH1 IAI1': ['IAH1', 'IAI1'], \n",
    "        'ILH1 ILI1': ['ILH1', 'ILI1'], \n",
    "        'INH1 INI1': ['INH1', 'INI1'], \n",
    "        'MOH1 MOI1': ['MOH1', 'MOI1'], \n",
    "        'MOH2 MOI2 MOI3': ['MOH2', 'MOI2', 'MOI3'], \n",
    "        'NEH1 NEI1': ['NEH1', 'NEI1'], \n",
    "        'NYH1 NYI1': ['NYH1', 'NYI1'], \n",
    "        'TXH1  TXI1  TXI2': ['TXH1', 'TXI1', 'TXI2'], \n",
    "        'TXH2  TXI3': ['TXH2', 'TXI3'], \n",
    "        'WIH1 WII1': ['WIH1', 'WII1']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864c852a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta [] \n",
      "phno [] \n",
      "wthr [] \n",
      "all  ['ARH1', 'ARH2', 'AZH1', 'AZI1', 'AZI2', 'COH1', 'DEH1', 'DEI1', 'G2FDE1', 'G2FIA3', 'G2FIL1', 'G2FIN1', 'G2FMN2', 'G2FNE1', 'G2FNY1', 'G2FWI-HYB', 'G2FWI1', 'G2FWI2', 'G2F_IN_TX1', 'GA2', 'GAH1', 'GAH2', 'GAI1', 'GAI2', 'GEH1', 'GEH2', 'GXE_inb_BO2', 'GXE_inb_IA1', 'GXE_inb_IA2', 'GXE_inb_MO1', 'GXE_inb_MO3', 'GxE_inb_PA1', 'IAH1', 'IAH1a', 'IAH1b', 'IAH1c', 'IAH2', 'IAH2 ', 'IAH3', 'IAH3 ', 'IAH4', 'IAH4 ', 'IAI1', 'IAI2', 'IAI3', 'IAI4', 'IAu2', 'IAu3', 'ILH1', 'ILH2', 'ILI1', 'INH1', 'INI1', 'KSH1', 'KSH2', 'KSH3', 'KSI1', 'MIH1', 'MNH1', 'MNI1', 'MNI2', 'MNu1', 'MOH1', 'MOH1 ', 'MOH1-Rep1', 'MOH1-Rep2', 'MOH2', 'MOI1', 'MOI2', 'MOI3', 'NC1', 'NCH1', 'NCI1', 'NEH1', 'NEH2', 'NEH3', 'NEH4', 'NEI1', 'NYH1', 'NYH1', 'NYH2', 'NYH3', 'NYH4', 'NYI1', 'NYI2', 'NYS1', 'NYu', 'OHH1', 'ONH1', 'ONH2', 'PAI1', 'PAI2', 'SCH1', 'SDH1', 'SDI1', 'TX3', 'TXH1', 'TXH1-Dry', 'TXH1-Early', 'TXH1-Late', 'TXH2', 'TXH3', 'TXH4', 'TXI1', 'TXI2', 'TXI3', 'W1H1', 'W1H2', 'WIH1', 'WIH2', 'WIH3', 'WII1', 'WII2']\n"
     ]
    }
   ],
   "source": [
    "# confirm everything's okay\n",
    "print(\n",
    "  'meta', find_unrecognized_experiments(meta.Experiment_Code, return_all_exps=False), \n",
    "'\\nphno', find_unrecognized_experiments(phno.Experiment_Code, return_all_exps=False),\n",
    "'\\nwthr', find_unrecognized_experiments(wthr.Experiment_Code, return_all_exps=False),\n",
    "'\\nall ', find_unrecognized_experiments([], return_all_exps=True)\n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94761eb",
   "metadata": {},
   "source": [
    "# Rearrange columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60621c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Experiment_Code', dtype('O'), dtype('O')),\n",
       " ('Plot_Length_Unit_Feet', dtype('float64'), dtype('float64')),\n",
       " ('Alley_Length_Unit_Inches', dtype('O'), dtype('int64')),\n",
       " ('Row_Spacing_Unit_Inches', dtype('float64'), dtype('int64')),\n",
       " ('Local_Check', dtype('O'), dtype('O')),\n",
       " ('Harvested_Unit_Datetime', dtype('O'), dtype('O')),\n",
       " ('Planted_Unit_Datetime', dtype('O'), dtype('O'))]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(e, meta.loc[:, e].dtype, phno.loc[:, e].dtype) for e in meta.columns if e in phno.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066db7f5",
   "metadata": {},
   "source": [
    "## Make mgmt from meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8c1630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out managment from metadata\n",
    "id_cols = ['Location_Name', 'Experiment_Code']\n",
    "mgmt_cols = ['Insecticide', 'Pre_Plant_Herbicide', 'Post_Plant_Herbicide', 'N_Unit_lbs_per_A', 'P_Unit_lbs_per_A', 'K_Unit_lbs_per_A', 'Nutrient_Schedule', 'Irrigation_Applied', 'Weather_Station_Documents_Irrigation', 'Fertigation_Schedule', 'Irrigation_Schedule']\n",
    "mgmt = meta.loc[:, ['Location_Name', 'Experiment_Code']+mgmt_cols].drop_duplicates()\n",
    "meta = meta.drop(columns=mgmt_cols)\n",
    "\n",
    "accumulator = mgmt.loc[:, id_cols].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cb31f3",
   "metadata": {},
   "source": [
    "### Fertilizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6d3d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = mgmt.loc[:, id_cols+[\n",
    "    'N_Unit_lbs_per_A', # |- total per season?\n",
    "    'P_Unit_lbs_per_A', # |\n",
    "    'K_Unit_lbs_per_A', # |\n",
    "    'Nutrient_Schedule']]\n",
    "\n",
    "for e in ['Application', 'Product', 'Date_Datetime', 'Amount_Per_Acre', 'Unit', 'Imputation_Notes']:\n",
    "    temp = safe_create_col(temp, e)\n",
    "    temp.loc[:, e] = temp.loc[:, e].astype('string')\n",
    "    \n",
    "temp.Date_Datetime = temp.Date_Datetime.astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b13dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix entries with information in total application columns but not in the Nutrient_Schedule\n",
    "application_lookup_list = [\n",
    "    ['MN', 'MNH1', '160 (N)'],\n",
    "    ['MO2', 'MOH2', '125 (N) 30 (P) 30 (K)'],\n",
    "    ['NE1', 'NEH1', '150 (N)'],\n",
    "    ['NE2', 'NEH2', '126 (N) 19.4 (P)'],\n",
    "    ['NE3', 'NEH3', '116 (N) 19.4 (P)'],\n",
    "    ['WI', 'G2FWI-HYB', '150 (N)'],\n",
    "    ['DE1', 'G2FDE1', '90 (N) 40 (P) 40 (K)'],\n",
    "    ['MO2', 'GXE_inb_BO2', '125 (N) 30 (P) 30 (K)'],\n",
    "    ['MO3', 'GXE_inb_MO3', '125 (N) 30 (P) 30 (K)'],\n",
    "    ['NE1', 'G2FNE1', '150 (N)'],\n",
    "    ['WI1', 'G2FWI1', '150 (N)'],\n",
    "    ['WI2', 'G2FWI2', '150 (N)']]\n",
    "\n",
    "for ee in application_lookup_list:\n",
    "    aa, bb, cc = ee[0], ee[1], ee[2]\n",
    "    mask = (temp.Location_Name == aa) & (temp.Experiment_Code == bb) \n",
    "    temp.loc[mask, 'Application'] = cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9661575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tricky one off\n",
    "mask = (temp.Location_Name == 'MN2') & (temp.Experiment_Code == 'G2FMN2') \n",
    "temp = temp.loc[~mask, ]\n",
    "temp = temp.merge(pd.DataFrame({\n",
    "    'Location_Name': ['MN2' for e in range(12)],\n",
    "    'Experiment_Code': ['G2FMN2' for e in range(12)],\n",
    "    'Replicate': [2, 4, 6, 8, 10, 12]+[1, 3, 5, 7, 9, 11],\n",
    "    'Application': ['0 (N)' for e in range(6)]+['100 (N)' for e in range(6)]\n",
    "}), how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75e70ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = temp.Nutrient_Schedule == 'Preplant 120 lb K2O/ac as 0-0-60; 117 lb PAN/ac as poultry litter; 194 lb P2O5/ac as poultry litter; At plant: 5/5/2014; 26 lb N/ac as 20-10-0-1; 13 lb P2O5/ac as 20-10-0-1; At sidedress: 195 lb N/ac as 30% UAN\\n'\n",
    "temp.loc[mask, :]\n",
    "temp = temp.loc[~mask, :]\n",
    "temp = temp.merge(pd.DataFrame({   \n",
    "    'Location_Name': ['DE', 'DE', 'DE'],\n",
    "  'Experiment_Code': ['DEH1', 'DEH1', 'DEH1'],\n",
    "      'Application': ['117 (N) 194 (P) 120 (K)', '26 (N), 13 (P)', '195 (N)'],\n",
    "    'Date_Datetime': ['', '5-5-2014', ''], \n",
    "             'Unit': ['lbs', 'lbs', 'lbs'],\n",
    " 'Imputation_Notes': ['Preplant', 'Planting', 'Sidedress']\n",
    "}\n",
    "), how = 'outer')\n",
    "\n",
    "\n",
    "mask = temp.Nutrient_Schedule == '3/24/2014 8/20/1930 broadcast 1000#/A; 4/4/2014 10-34-0 row band 10gal/A; 4/4/2014 Agri Starter Orangeburg row band 4qt/A; 5/7/2014;28-0-0-0.5;row band;100#N/A; 5/7/2014;Boron;row band;20 ounce/A; 5/14/2014;28-0-0-0.5;row band;100#N/A'\n",
    "temp = temp.loc[~mask, :]\n",
    "temp = temp.merge(pd.DataFrame({   \n",
    "    'Location_Name': ['GA',        'GA',       'GA',         'GA',         'GA',       'GA'],\n",
    "  'Experiment_Code': ['GAH1',      'GAH1',     'GAH1',       'GAH1',       'GAH1',     'GAH1'],\n",
    "      'Application': ['8-20-30',   '10-34-0',  'Orangeburg', '28-0-0-0.5', 'Boron',    '28-0-0-0.5' ],\n",
    "    'Date_Datetime': ['3/24/2014', '4/4/2014', '4/4/2014',   '5/7/2014',   '5/7/2014', '5/14/2014'], \n",
    "  'Amount_Per_Acre': [1000,        10,         4,            100,          20,         100   ], \n",
    "             'Unit': ['lbs',       'gal',      'qt',         'lbs',        'oz',       'lbs' ]\n",
    "}\n",
    "), how = 'outer')\n",
    "\n",
    "mask = temp.Nutrient_Schedule == '5/8:  140-0-0'\n",
    "temp.loc[mask, ['Product', 'Date_Datetime', 'Nutrient_Schedule']] = [' 140-0-0', '5-8-2014', np.nan] # MDY\n",
    "\n",
    "mask = temp.Nutrient_Schedule == '4/22:  dry fert 36-92-120; 4/23: 150 lbs Ammonia'\n",
    "temp = temp.loc[~mask, :]\n",
    "temp = temp.merge(pd.DataFrame({   \n",
    "    'Location_Name': ['IA4', 'IA4'],\n",
    "  'Experiment_Code': ['IAH4', 'IAH4'],\n",
    "      'Application': ['36-92-120', 'Ammonia'],\n",
    "    'Date_Datetime': ['4/22', '4/23'], \n",
    "  'Amount_Per_Acre': [100,     150], \n",
    "             'Unit': ['lbs', 'lbs']\n",
    "}\n",
    "), how = 'outer')\n",
    "\n",
    "\n",
    "\n",
    "mask = temp.Nutrient_Schedule == '180 lb Nitrogen/acre preplant'\n",
    "temp.loc[mask, ['Product', 'Imputation_Notes', 'Nutrient_Schedule']] = [' 180', 'Preplant', np.nan]\n",
    "\n",
    "\n",
    "mask = temp.Nutrient_Schedule == '300#/acre of 10-0-30-12%S preplant and 26 gallons of 30% UAN (85# of N) was applied pre- emerge. Total N applied was 115 pounds per acre.'\n",
    "temp = temp.loc[~mask, :]\n",
    "temp = temp.merge(pd.DataFrame({   \n",
    "    'Location_Name': ['NC', 'NC'],\n",
    "  'Experiment_Code': ['NCH1', 'NCH1'],\n",
    "      'Application': ['10-0-30-12%S', 'N'],\n",
    "  'Amount_Per_Acre': [300, 85], \n",
    "             'Unit': ['lbs', 'lbs'],\n",
    " 'Imputation_Notes': ['Preplant', 'Pre-emerge']\n",
    "}\n",
    "), how = 'outer')\n",
    "\n",
    "mask = temp.Nutrient_Schedule == 'none other than preplant above'\n",
    "temp.loc[mask, ['Product', 'Unit', 'Imputation_Notes', 'Nutrient_Schedule']] = ['118 (N) 46 (P) 62 (K)', 'lbs', 'Preplant', np.nan]\n",
    "\n",
    "\n",
    "mask = temp.Nutrient_Schedule == 'NOTES on fertilizer:  At planting 5/27/14 12-25-0-3.3S and 0.3 ZN was banded at 7.5 gallons per acre which comes out to 11 lbs of N and 22 lbs of P2O per acre.  Then side dress 6/30/14 33.8 gallons of 30 % UAN which is 110 lbs of N.'\n",
    "temp = temp.loc[~mask, :]\n",
    "temp = temp.merge(pd.DataFrame({   \n",
    "    'Location_Name': ['NY1', 'NY1', 'NY1'],\n",
    "  'Experiment_Code': ['NYH1', 'NYH1', 'NYH1'],\n",
    "      'Application': ['12-25-0-3.3S', '0.3 Zn', 'N'],\n",
    "    'Date_Datetime': ['5/27/14', '5/27/14', '6/30/14'], \n",
    "  'Amount_Per_Acre': [91.66666666666667, np.nan, 110], \n",
    "             'Unit': ['lbs','lbs','lbs']\n",
    "}\n",
    "), how = 'outer')\n",
    "\n",
    "\n",
    "mask = temp.Nutrient_Schedule == '250 lbs/acre of 10-20-20 / 110lbs/acre  N 33.8 gallons of 30% UAN'\n",
    "temp.loc[mask, ['Product', 'Unit', 'Nutrient_Schedule']] = ['135.1204 (N) 50 (P) 50 (K)', 'lbs', np.nan]\n",
    "\n",
    "mask = temp.Nutrient_Schedule == 'P&K applied in fall 2013; Liquid N applied preplant;  Dry starter fertilizer applied with planter'\n",
    "temp.loc[mask, ['Product', 'Unit', 'Nutrient_Schedule']] = ['175 (N) 68 (P) 120 (K)', 'kg/ha', np.nan]\n",
    "\n",
    "mask = temp.Nutrient_Schedule == 'UAN broadcast Preplant/ P+K 2x2 band Starter Fertilizer'\n",
    "temp.loc[mask, ['Product', 'Unit', 'Nutrient_Schedule']] = ['165 (N) 54 (P) 12024 (K)', 'lbs', np.nan]\n",
    "\n",
    "mask = temp.Nutrient_Schedule == 'Preplant applied at 150 lbs 11-37-0+4lbs Zn then applied at V7 = 200 lbs 46-0-0'\n",
    "temp = temp.loc[~mask, :]\n",
    "temp = temp.merge(pd.DataFrame({   \n",
    "    'Location_Name': ['TX1', 'TX1', 'TX1'],\n",
    "  'Experiment_Code': ['TXH1', 'TXH1', 'TXH1'],\n",
    "      'Application': ['11-37-0', 'Zn', 'N'],\n",
    "  'Amount_Per_Acre': [150, 41, 92], \n",
    "             'Unit': ['lbs','lbs','lbs'],\n",
    " 'Imputation_Notes': ['Preplant', 'Preplant', 'V7']\n",
    "}\n",
    "), how = 'outer')\n",
    "\n",
    "\n",
    "mask = temp.Nutrient_Schedule == '3/6/14-UAN/10-34-0 applied with spreader truck. V5 stage 32-0-0 applied side dress'\n",
    "temp = temp.loc[~mask, :]\n",
    "temp = temp.merge(pd.DataFrame({   \n",
    "    'Location_Name': ['TX2', 'TX2'],\n",
    "  'Experiment_Code': ['TXH2', 'TXH2'],\n",
    "      'Application': ['10-34-0', 'N'],\n",
    "    'Date_Datetime': ['3/6/14', ''], \n",
    "  'Amount_Per_Acre': [235.2941176470588, 276.47058823529414], \n",
    "             'Unit': ['lbs','lbs']\n",
    "}\n",
    "), how = 'outer')\n",
    "temp = temp.merge(pd.DataFrame({   \n",
    "    'Location_Name': ['TX3', 'TX3'],\n",
    "  'Experiment_Code': ['TX3', 'TX3'],\n",
    "      'Application': ['10-34-0', 'N'],\n",
    "    'Date_Datetime': ['3/6/14', ''], \n",
    "  'Amount_Per_Acre': [235.2941176470588, 276.47058823529414], \n",
    "             'Unit': ['lbs','lbs']\n",
    "}\n",
    "), how = 'outer')\n",
    "\n",
    "\n",
    "mask = temp.Nutrient_Schedule == '120 lbs/acre'\n",
    "temp.loc[mask, ['Product', 'Unit', 'Nutrient_Schedule']] = ['120 (N)', 'lbs', np.nan]\n",
    "\n",
    "\n",
    "mask = temp.Nutrient_Schedule == 'none other than applied in fall'\n",
    "temp = temp.loc[~mask, :]\n",
    "temp = temp.merge(pd.DataFrame({   \n",
    "    'Location_Name': ['IA3', 'IA3'],\n",
    "  'Experiment_Code': ['G2FIA3', 'G2FIA3'],\n",
    "      'Application': ['22 (N) 74 (P) 111 (K)', '110 (N)'],\n",
    "             'Unit': ['lbs','lbs'],\n",
    " 'Imputation_Notes': ['fall 2013', 'spring 2014']\n",
    "}\n",
    "), how = 'outer')\n",
    "\n",
    "\n",
    "mask = temp.Nutrient_Schedule == 'Pre plant incorporated fertilizer 10-10-30 at 474 lbs per acre; 24S liquid nitrogen 12 gals per acre side dress; 24S liquid nitrogen 12 gals per acre top dress'\n",
    "temp.loc[mask, ['Product', 'Unit', 'Nutrient_Schedule']] = ['100 (N) 47.4 (P) 142.2 (K)', 'lbs', np.nan]\n",
    "\n",
    "\n",
    "mask = temp.Nutrient_Schedule == 'NOTES on fertilizer:  At planting 5/27/14 12-25-0-3.3S and 0.3 ZN was banded at 7.5 gallons per acre which comes out to 11 lbs of N and 22 lbs of P2O per acre.\\xa0 Then side dress 6/30/14 33.8 gallons of 30 % UAN which is 110 lbs of N.'\n",
    "temp = temp.loc[~mask, :]\n",
    "temp = temp.merge(pd.DataFrame({   \n",
    "    'Location_Name': ['NY1', 'NY1', 'NY1'],\n",
    "  'Experiment_Code': ['G2FNY1', 'G2FNY1', 'G2FNY1'],\n",
    "      'Application': ['12-25-0-3.3S', '0.3 Zn', 'N'],\n",
    "    'Date_Datetime': ['5/27/14', '5/27/14', '6/30/14'], \n",
    "  'Amount_Per_Acre': [91.66666666666667, np.nan, 110], \n",
    "             'Unit': ['lbs','lbs','lbs']\n",
    "}\n",
    "), how = 'outer')\n",
    "\n",
    "\n",
    "mask = temp.Nutrient_Schedule == 'Pre-plant (150 lbs 11-37-0 + 4lbs Zn) applied on 1/19/2014 in liquid form; and 200 lbs 32-0-0 applied in liquid form on 4-19-2014 ~V-7.'\n",
    "temp = temp.loc[~mask, :]\n",
    "temp = temp.merge(pd.DataFrame({   \n",
    "    'Location_Name': ['TX1', 'TX1', 'TX1'],\n",
    "  'Experiment_Code': ['G2F_IN_TX1', 'G2F_IN_TX1', 'G2F_IN_TX1'],\n",
    "      'Application': ['11-37-0', 'Zn', 'N'],\n",
    "    'Date_Datetime': ['1/19/2014', '1/19/2014', '4/19/2014'], \n",
    "  'Amount_Per_Acre': [150, 4, 64,], \n",
    "             'Unit': ['lbs','lbs','lbs']\n",
    "}\n",
    "), how = 'outer')\n",
    "\n",
    "\n",
    "mask = temp.Nutrient_Schedule == 'Pre-plant (150 lbs 11-37-0 + 4lbs Zn) applied on 1/29/2014 in liquid form; and 200 lbs 32-0-0 applied in liquid form on 4-15-2014.'\n",
    "temp = temp.loc[~mask, :]\n",
    "temp = temp.merge(pd.DataFrame({   \n",
    "    'Location_Name': ['TX2', 'TX2', 'TX2'],\n",
    "  'Experiment_Code': ['G2F_IN_TX1', 'G2F_IN_TX1', 'G2F_IN_TX1'],\n",
    "      'Application': ['11-37-0', 'Zn', 'N'],\n",
    "    'Date_Datetime': ['1/29/2014', '1/29/2014', '4/15/2014'], \n",
    "  'Amount_Per_Acre': [150, 4, 64,], \n",
    "             'Unit': ['lbs','lbs','lbs']\n",
    "}\n",
    "), how = 'outer')\n",
    "\n",
    "\n",
    "mask = temp.Nutrient_Schedule == \"fall '13:  NH3; 4/12:  11-52-0  Map; 0-0-60 granular potash\"\n",
    "temp = temp.loc[~mask, :]\n",
    "temp = temp.merge(pd.DataFrame({   \n",
    "    'Location_Name': ['IA1'],\n",
    "  'Experiment_Code': ['IAH1'],\n",
    "      'Application': ['156 (N) 80 (P) 75 (K)'],\n",
    "    'Date_Datetime': ['4/12/2014'], \n",
    "             'Unit': ['lbs']\n",
    "}\n",
    "), how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8000cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (temp.Nutrient_Schedule == 'see above')\n",
    "temp.loc[mask, 'Application'] = '198 (N) 46 (P)'\n",
    "\n",
    "mask = temp.Nutrient_Schedule == 'See above'\n",
    "temp.loc[mask, ['Application', 'Date_Datetime']] = ['450 (N) 192 (P) 210 (K)', '4/17/2014'] \n",
    "\n",
    "mask = temp.Nutrient_Schedule == 'Low-N history of fields 105 and 85: Fields 105 and 85 recieved an application of hardwood sawdust (May 6 field 85 and May 9 field 105) in 2011; and both fields received a second application of sawdust on May 23; 2012: not sawdust applied in 2013 or 2014'\n",
    "temp.loc[mask, ['Imputation_Notes', 'Nutrient_Schedule']] = ['Inconsistant withing field. Recommend Dropping.', np.nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f14979",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp.loc[:, ['Location_Name', 'Experiment_Code', \n",
    "             'Application', 'Product', 'Date_Datetime', 'Amount_Per_Acre', 'Unit',\n",
    "             'Imputation_Notes', 'Replicate']]\n",
    "temp.loc[temp.Unit.isna(), 'Unit'] = 'lbs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd4b342",
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulator = accumulator.merge(temp, \n",
    "                                how = 'outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635036e7",
   "metadata": {},
   "source": [
    "### Irrigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c186a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = mgmt.loc[:, id_cols+[\n",
    "    'Irrigation_Applied',\n",
    "    'Weather_Station_Documents_Irrigation',\n",
    "    'Fertigation_Schedule',\n",
    "    'Irrigation_Schedule']]\n",
    "\n",
    "for e in ['Application', 'Product', 'Date_Datetime', 'Amount_Per_Acre', 'Unit', 'Imputation_Notes']:\n",
    "    temp = safe_create_col(temp, e)\n",
    "    temp.loc[:, e] = temp.loc[:, e].astype('string')\n",
    "    \n",
    "temp.Date_Datetime = temp.Date_Datetime.astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4227caf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location_Name</th>\n",
       "      <th>Experiment_Code</th>\n",
       "      <th>Irrigation_Applied</th>\n",
       "      <th>Weather_Station_Documents_Irrigation</th>\n",
       "      <th>Fertigation_Schedule</th>\n",
       "      <th>Irrigation_Schedule</th>\n",
       "      <th>Application</th>\n",
       "      <th>Product</th>\n",
       "      <th>Date_Datetime</th>\n",
       "      <th>Amount_Per_Acre</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Imputation_Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TX1</td>\n",
       "      <td>TXH1</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>none</td>\n",
       "      <td>4/29/2014 and 6/17/2014; flood irrigated</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TX1</td>\n",
       "      <td>G2F_IN_TX1</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>none</td>\n",
       "      <td>May 4; 2014 and June 19; 2014; flood irrigated</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Location_Name Experiment_Code Irrigation_Applied  \\\n",
       "19           TX1            TXH1                yes   \n",
       "37           TX1      G2F_IN_TX1                yes   \n",
       "\n",
       "   Weather_Station_Documents_Irrigation Fertigation_Schedule  \\\n",
       "19                                   no                 none   \n",
       "37                                   no                 none   \n",
       "\n",
       "                               Irrigation_Schedule Application Product  \\\n",
       "19        4/29/2014 and 6/17/2014; flood irrigated        <NA>    <NA>   \n",
       "37  May 4; 2014 and June 19; 2014; flood irrigated        <NA>    <NA>   \n",
       "\n",
       "   Date_Datetime Amount_Per_Acre  Unit Imputation_Notes  \n",
       "19          <NA>            <NA>  <NA>             <NA>  \n",
       "37          <NA>            <NA>  <NA>             <NA>  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only need to consider those with records not traced by the weather station\n",
    "temp = temp.loc[temp.Irrigation_Applied.isin(['Yes', 'yes'])]\n",
    "temp = temp.loc[temp.Irrigation_Schedule.notna()]\n",
    "temp = temp.loc[temp.Weather_Station_Documents_Irrigation.isin(['no'])]\n",
    "\n",
    "# TX1 (Experiment_Code: TXH1 and G2F_IN_TX1) had \n",
    "# '4/29/2014 and 6/17/2014; flood irrigated',\n",
    "# 'May 4; 2014 and June 19; 2014; flood irrigated'\n",
    "# but have no values recorded for amount\n",
    "\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a41eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulator = accumulator.merge(pd.DataFrame({   \n",
    "    'Location_Name': ['TX1' for e in range(4)],\n",
    "  'Experiment_Code': ['TXH1', 'TXH1', 'G2F_IN_TX1', 'G2F_IN_TX1'],\n",
    "      'Application': ['water' for e in range(4)],\n",
    "    'Date_Datetime': ['4/29/2014', '6/17/2014', '5/4/2014', '6/19/2014']\n",
    "}\n",
    "), how = 'outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca9ba4e",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3599b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = mgmt.loc[:, id_cols+[\n",
    "    'Insecticide',\n",
    "    'Pre_Plant_Herbicide',\n",
    "    'Post_Plant_Herbicide']]\n",
    "mgmt = accumulator.merge(temp, how = 'outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7b2e05",
   "metadata": {},
   "source": [
    "## Return to Standard Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdeba21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate static and dynamic values\n",
    "sval = phno.merge(meta.drop(columns=[\n",
    "    'Alley_Length_Unit_Inches', # allow phno to be the authorative source of alley length (also avoids IA3's meta value of ['120\" & 30\"'])\n",
    "    'Plot_Length_Unit_Feet',\n",
    "    'Row_Spacing_Unit_Inches',\n",
    "    'Local_Check',\n",
    "    'Harvested_Unit_Datetime',\n",
    "    'Planted_Unit_Datetime'\n",
    "    ]), how = 'outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a94f13",
   "metadata": {},
   "source": [
    "# Sanitize Non-ID columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcc8720",
   "metadata": {},
   "source": [
    "## Sanitization functions\n",
    "\n",
    "The pattern to use is:\n",
    " 1. Alter the dataframe\n",
    " 1. Test the dataframe against expectations\n",
    " \n",
    "The main tasks that need to be completed are:\n",
    " 1. Identify values that can't be converted to the expected data type. The \"find_unconvertable_\" family of functions should be used. \n",
    "     1. `find_unconvertable_datetimes`\n",
    "     \n",
    " 1. For simple renaming (e.g. misspellings) or splitting non-tidy data into two rows (\"entry1-entry2\" -> \"entry1\", \"entry2\") use `sanitize_col` \n",
    " 1. Move values that are ambigous but pertain to data imputation to \"Imputation_Notes\" using `relocate_to_Imputation_Notes`\n",
    " 1. If new columns need to be added (e.g. mgmt.Ingredient for parsed components of Product (e.g. elements) ) this should be accomplished with `safe_create_col`.\n",
    " 1. Any one off changes should be accomplised manually. \n",
    " 1. Confirm columns match the expected types with `check_df_dtype_expectations`, and report mismatches. \n",
    "\n",
    "\n",
    "These steps should be completed for each dataframe in turn to minimize the cognitive load of the reader. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cad031",
   "metadata": {},
   "source": [
    "## Sanitization: Column data type expectations\n",
    "Note: to handle missing values some columns that would otherwise be ints are floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40b6f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "sval_col_dtypes = mk_dtype_dict(name = 'sval')\n",
    "wthr_col_dtypes = mk_dtype_dict(name = 'wthr')\n",
    "mgmt_col_dtypes = mk_dtype_dict(name = 'mgmt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972cfb9f",
   "metadata": {},
   "source": [
    "# Sanitization: Alter entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccee17b",
   "metadata": {},
   "source": [
    "## Static values (within season)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ab9954",
   "metadata": {},
   "source": [
    "### Datetime containing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d2d163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert the date cols into datetime. Lean on pd.to_datetime() to infer the format, assume that each site uses the same format.\n",
    "\n",
    "for e in ['Planted_Unit_Datetime',\n",
    "          'Harvested_Unit_Datetime',\n",
    "          'Anthesis_Unit_Datetime',\n",
    "          'Silking_Unit_Datetime',\n",
    "    ]:\n",
    "# find_unconvertable_datetimes(df_col=sval[e], pattern='%Y-%m-%d %H:%M', index=False)\n",
    "\n",
    "    sval['Datetime_Temp'] = pd.to_datetime(np.nan)\n",
    "\n",
    "    for code in list(sval.Experiment_Code.drop_duplicates()):\n",
    "    # code = list(sval.Experiment_Code.drop_duplicates())[0]\n",
    "        sval.loc[sval.Experiment_Code == code, 'Datetime_Temp'\n",
    "                 ] = pd.to_datetime(sval.loc[sval.Experiment_Code == code, e])\n",
    "\n",
    "    sval.loc[:, e] = sval.loc[:, 'Datetime_Temp'] \n",
    "\n",
    "sval = sval.drop(columns = 'Datetime_Temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa07a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> floats\n",
    "# find_unconvertable_numerics(df_col = sval['Soil_1_to_1_Unit_pH'], index = False)\n",
    "sval = sanitize_col(\n",
    "    df = sval, \n",
    "    col = 'Soil_1_to_1_Unit_pH', \n",
    "    simple_renames= {'PH = 8.00': '8.0', \n",
    "                     'not recently tested': '', \n",
    "                     'soil sample submitted 6/11/15': ''}, \n",
    "    split_renames= {})\n",
    "\n",
    "sval.loc[sval.Soil_1_to_1_Unit_pH == '', 'Soil_1_to_1_Unit_pH'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79c1a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert types\n",
    "for e in ['Soil_1_to_1_Unit_pH']:\n",
    "    err_list = find_unconvertable_numerics(df_col = sval[e], index = False)\n",
    "    if err_list != []:\n",
    "        print(e)\n",
    "        print(err_list)\n",
    "    else:\n",
    "        sval[e] = sval[e].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826b9321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to bool\n",
    "sval = sanitize_col(\n",
    "    df = sval, \n",
    "    col = 'Discarded', \n",
    "    simple_renames= {\n",
    "        'Yes':'True',\n",
    "        'yes':'True'}, \n",
    "    split_renames= {})\n",
    "\n",
    "# set missing to false\n",
    "sval.loc[sval.Discarded.isna(), 'Discarded'] = 'False'\n",
    "sval.Discarded = sval.Discarded.map({'True': True, 'False': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e4df11",
   "metadata": {},
   "source": [
    "### Simple Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6927f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to float\n",
    "# sval.Pounds_Needed_Soil_Moisture.astype(float)\n",
    "sval = sval.drop(columns=[\n",
    "    'Drop_Record_Index',\n",
    "    'Inbred_Reps',\n",
    "    'Inbred_Plots',\n",
    "    'Collaborator',\n",
    "    'File_Name',\n",
    "    'Traits_Measured',\n",
    "    'Folder_Name',\n",
    "    'Metadata_File',\n",
    "    'Additional_Metadata',\n",
    "    'Weather_Directory',\n",
    "    'Additional_Metics'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9768e7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to bool\n",
    "sval['phno'] = sval['phno'].astype('bool')\n",
    "sval['meta'] = sval['meta'].astype('bool')\n",
    "\n",
    "# to string\n",
    "sval = cols_astype_string(\n",
    "    df = sval, \n",
    "    col_list = [key for key in sval_col_dtypes.keys() if sval_col_dtypes[key] == 'string'])\n",
    "\n",
    "sval.Year = year_string\n",
    "sval.Year = sval.Year.astype('string')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55b1261",
   "metadata": {},
   "source": [
    "### Check Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec742610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 Columns pass.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = check_df_dtype_expectations(df = sval, dtype_dct = sval_col_dtypes)\n",
    "\n",
    "if sum(checkpoint.Pass)/checkpoint.shape[0] == 1:\n",
    "    pass\n",
    "else:\n",
    "    print(checkpoint.loc[~checkpoint.Pass, ]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54014602",
   "metadata": {},
   "source": [
    "## Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af31085f",
   "metadata": {},
   "source": [
    "### Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b87be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... or we use the fields in the df to make a consistent format\n",
    "wthr = cols_astype_string(\n",
    "    df = wthr, \n",
    "    col_list = ['Year', 'Month', 'Day', 'Time'])\n",
    "\n",
    "wthr['Datetime_Temp'] = wthr['Year']+'-'+wthr['Month']+'-'+wthr['Day']+' '+wthr['Time']\n",
    "\n",
    "# # convert types\n",
    "err_list = find_unconvertable_datetimes(df_col=wthr['Datetime_Temp'], pattern='%Y-%m-%d %H:%M', index=False)\n",
    "if err_list != []:\n",
    "    print(err_list)\n",
    "else:\n",
    "    wthr.Datetime_Temp = pd.to_datetime(pd.Series(wthr.Datetime_Temp), errors='coerce')\n",
    "    wthr.Datetime = wthr.Datetime_Temp\n",
    "    wthr = wthr.drop(columns= 'Datetime_Temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64613664",
   "metadata": {},
   "source": [
    "### Data_Cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d9bb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to bool\n",
    "wthr = sanitize_col(\n",
    "    df = wthr, \n",
    "    col = 'Data_Cleaned', \n",
    "    simple_renames= {\n",
    "        'Yes':'True',\n",
    "        'No':'False'}, \n",
    "    split_renames= {})\n",
    "\n",
    "# set missing to false\n",
    "wthr.loc[wthr.Data_Cleaned.isna(), 'Data_Cleaned'] = 'False'\n",
    "wthr.Data_Cleaned = wthr.Data_Cleaned.map({'True': True, 'False': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ccd74b",
   "metadata": {},
   "source": [
    "### Simple Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed990b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wthr = wthr.drop(columns = 'Drop_Record_Index')\n",
    "\n",
    "# to string\n",
    "wthr = cols_astype_string(\n",
    "    df = wthr, \n",
    "    col_list = [key for key in wthr_col_dtypes.keys() if wthr_col_dtypes[key] == 'string'])\n",
    "\n",
    "wthr.Year = year_string\n",
    "wthr.Year = wthr.Year.astype('string')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801ad550",
   "metadata": {},
   "source": [
    "### Check Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53fd6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 Columns pass.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = check_df_dtype_expectations(df = wthr, dtype_dct = wthr_col_dtypes)\n",
    "\n",
    "if sum(checkpoint.Pass)/checkpoint.shape[0] == 1:\n",
    "    pass\n",
    "else:\n",
    "    print(checkpoint.loc[~checkpoint.Pass, ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1958033e",
   "metadata": {},
   "source": [
    "## Management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcf1a42",
   "metadata": {},
   "source": [
    "### Date_Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f7fe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgmt = sanitize_col(\n",
    "    df = mgmt, \n",
    "    col = 'Date_Datetime', \n",
    "    simple_renames= {\n",
    "        '5-5-2014': '5/5/2014',\n",
    "        '5-8-2014': '5/8/2014',\n",
    "        '4/22': '4/22/2014',\n",
    "        '4/23': '4/23/2014',\n",
    "        '5/27/14': '5/27/2014',\n",
    "        '6/30/14': '6/30/2014',\n",
    "        '3/6/14': '3/6/2014'\n",
    "    }, \n",
    "    split_renames= {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd0e2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgmt.loc[mgmt.Date_Datetime.isna(), 'Date_Datetime'] = np.nan\n",
    "mgmt.loc[mgmt.Date_Datetime == '', 'Date_Datetime'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1736eb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_unconvertable_datetimes(mgmt.Date_Datetime, pattern='%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c69025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b612643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert types\n",
    "err_list = find_unconvertable_datetimes(df_col=mgmt.Date_Datetime, pattern='%m/%d/%Y', index=False)\n",
    "if err_list != []:\n",
    "    print(err_list)\n",
    "else:\n",
    "    mgmt.Date_Datetime = pd.to_datetime(pd.Series(mgmt.Date_Datetime), format = '%m/%d/%Y', errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497e0f42",
   "metadata": {},
   "source": [
    "### Amount_Per_Acre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc11303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert types\n",
    "err_list = find_unconvertable_numerics(df_col = mgmt['Amount_Per_Acre'], index = False)\n",
    "if err_list != []:\n",
    "    print(err_list)\n",
    "else:\n",
    "    mgmt.Amount_Per_Acre = pd.to_numeric(mgmt.Amount_Per_Acre, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57973e80",
   "metadata": {},
   "source": [
    "### Ingredient\n",
    "This is to be the cleaned up version of the \"Product\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66140777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(mgmt.loc[:, 'Ingredient'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829c3e99",
   "metadata": {},
   "source": [
    "### Simple Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb60d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to bool\n",
    "# mgmt['mgmt'] = mgmt['mgmt'].astype('bool')\n",
    "\n",
    "# to string\n",
    "for e in [ee for ee in ['Application', 'Product', 'Ingredient', 'Unit', 'Imputation_Notes',\n",
    "                       'Location_Name', 'Experiment_Code', 'Replicate', 'Insecticide', 'Pre_Plant_Herbicide', 'Post_Plant_Herbicide'] if ee in mgmt.columns]:\n",
    "    mgmt[e] = mgmt[e].astype('string')\n",
    "    \n",
    "\n",
    "mgmt.Year = year_string\n",
    "# mgmt.Year = mgmt.Year.astype('string')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b2160e",
   "metadata": {},
   "source": [
    "### Check Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1578ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 Columns pass.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = check_df_dtype_expectations(df = mgmt, dtype_dct = mgmt_col_dtypes)\n",
    "\n",
    "if sum(checkpoint.Pass)/checkpoint.shape[0] == 1:\n",
    "    pass\n",
    "else:\n",
    "    print(checkpoint.loc[~checkpoint.Pass, ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3109ee8b",
   "metadata": {},
   "source": [
    "# Publish\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf01fde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_out_pkl(obj = sval, path = './data/interim/'+year_string+'sval.pickle')\n",
    "write_out_pkl(obj = wthr, path = './data/interim/'+year_string+'wthr.pickle')\n",
    "write_out_pkl(obj = mgmt, path = './data/interim/'+year_string+'mgmt.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
