{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce112a12",
   "metadata": {},
   "source": [
    "# Process Data from 2015 into a consistent format.\n",
    "\n",
    "> This notebook brings the 2015 into alignment with the desired format with respect to field name, type, and grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9bf5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports ----\n",
    "import re\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf3e182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from g2fd.internal import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569c88f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp internal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1692f5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2015\n",
    "year_string = '2015'\n",
    "\n",
    "          # print('Note! Many management factors are recorded in 2015!')\n",
    "meta_path = './data/raw/G2F_Planting_Season_2015_v2/z._2015_supplemental_info/g2f_2015_field_metadata.csv' \n",
    "phno_path = './data/raw/G2F_Planting_Season_2015_v2/a._2015_hybrid_phenotypic_data/g2f_2015_hybrid_data_clean.csv' \n",
    "# geno_path = None,  \n",
    "wthr_path = './data/raw/G2F_Planting_Season_2015_v2/b._2015_weather_data/g2f_2015_weather.csv'\n",
    "soil_path = './data/raw/G2F_Planting_Season_2015_v2/d._2015_soil_data/g2f_2015_soil_data.csv'\n",
    "          # There is data to be had but it's not formatted in a machine friendly way.\n",
    "          # I've reformatted it to be easy to read in.\n",
    "mgmt_path = './data/Manual_old/g2f_2015_agronomic information.csv'\n",
    "\n",
    "meta = pd.read_csv(meta_path, encoding = \"ISO-8859-1\", low_memory=False)\n",
    "phno = pd.read_csv(phno_path, encoding = \"ISO-8859-1\", low_memory=False)\n",
    "wthr = pd.read_csv(wthr_path, encoding = \"ISO-8859-1\", low_memory=False)\n",
    "soil = pd.read_csv(soil_path, encoding = \"ISO-8859-1\", low_memory=False)\n",
    "mgmt = pd.read_csv(mgmt_path, encoding = \"ISO-8859-1\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d31cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dicts for column renaming\n",
    "meta_name_dict = mk_name_dict(name = 'meta')\n",
    "phno_name_dict = mk_name_dict(name = 'phno')\n",
    "soil_name_dict = mk_name_dict(name = 'soil')\n",
    "wthr_name_dict = mk_name_dict(name = 'wthr')\n",
    "mgmt_name_dict = mk_name_dict(name = 'mgmt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1ab577",
   "metadata": {},
   "source": [
    "# Rename\n",
    "**Naming rules:**\n",
    "- One dict for each input df\n",
    "- Comment out anything that shouldn't be changed\n",
    "- Upper_Upper_Unit_\\$unit\n",
    "- Upper_$number\n",
    "- No special characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0b0a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [], [], [], [])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(find_unrecognized_columns(df = meta, dct = meta_name_dict),\n",
    "find_unrecognized_columns(df = phno, dct = phno_name_dict),\n",
    "find_unrecognized_columns(df = soil, dct = soil_name_dict),\n",
    "find_unrecognized_columns(df = wthr, dct = wthr_name_dict),\n",
    "find_unrecognized_columns(df = mgmt, dct = mgmt_name_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9080f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = meta.rename(columns=meta_name_dict)\n",
    "phno = phno.rename(columns=phno_name_dict)\n",
    "soil = soil.rename(columns=soil_name_dict)\n",
    "wthr = wthr.rename(columns=wthr_name_dict)\n",
    "mgmt = mgmt.rename(columns=mgmt_name_dict)\n",
    "\n",
    "# add indicator columns to help with debugging merge\n",
    "meta['meta'] = True\n",
    "phno['phno'] = True\n",
    "soil['soil'] = True\n",
    "wthr['wthr'] = True\n",
    "mgmt['mgmt'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485b4fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(54, 44), (13693, 39), (48, 12), (220044, 30), (157, 11)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e.shape for e in [meta, phno, soil, wthr, mgmt]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1589ac0",
   "metadata": {},
   "source": [
    "# Sanatize ID columns as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca242c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_rename_dict = {\n",
    "    'IA(H4)': 'IAH4', \n",
    "    'MN(?)1': 'MNu1', \n",
    "    'IA(?)3': 'IAu3', \n",
    "    'NY?': 'NYu', \n",
    "    'IA(?)2': 'IAu2'    \n",
    "}\n",
    "\n",
    "split_rename_dict = {\n",
    "    'NEH1  NEH4': ['NEH1', 'NEH4'], \n",
    "    'KSH1  KSI1': ['KSH1', 'KSI1'], \n",
    "    'AZI1  AZI2': ['AZI1', 'AZI2'], \n",
    "    'PAI1  PAI2': ['PAI1', 'PAI2'], \n",
    "    'WIH1  WII1': ['WIH1', 'WII1'], \n",
    "    'WIH2  WII2': ['WIH2', 'WII2'], \n",
    "    'INH1  INI1': ['INH1', 'INI1'], \n",
    "    'NYH1  NYI1': ['NYH1', 'NYI1'], \n",
    "    'NYH3  NYI2': ['NYH3', 'NYI2'],  \n",
    "    'ILH1  ILI1  ILH2': ['ILH1', 'ILI1', 'ILH2'],\n",
    "    'TXH1  TXI1  TXI2': ['TXH1', 'TXI1', 'TXI2'],\n",
    "    'MOH1  MOI1  MOH2  MOI2': ['MOH1', 'MOI1', 'MOH2', 'MOI2']\n",
    "}\n",
    "\n",
    "soil = sanitize_Experiment_Codes(\n",
    "    df = soil, \n",
    "    simple_renames = simple_rename_dict, \n",
    "    split_renames = split_rename_dict)\n",
    "\n",
    "wthr = sanitize_Experiment_Codes(\n",
    "    df = wthr, \n",
    "    simple_renames = simple_rename_dict, \n",
    "    split_renames = split_rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864c852a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta [] \n",
      "phno [] \n",
      "soil [] \n",
      "wthr [] \n",
      "mgmt [] \n",
      "all  ['ARH1', 'ARH2', 'AZH1', 'AZI1', 'AZI2', 'COH1', 'DEH1', 'DEI1', 'G2FDE1', 'G2FIA3', 'G2FIL1', 'G2FIN1', 'G2FMN2', 'G2FNE1', 'G2FNY1', 'G2FWI-HYB', 'G2FWI1', 'G2FWI2', 'G2F_IN_TX1', 'GA2', 'GAH1', 'GAH2', 'GAI1', 'GAI2', 'GEH1', 'GEH2', 'GXE_inb_BO2', 'GXE_inb_IA1', 'GXE_inb_IA2', 'GXE_inb_MO1', 'GXE_inb_MO3', 'GxE_inb_PA1', 'IAH1', 'IAH1a', 'IAH1b', 'IAH1c', 'IAH2', 'IAH2 ', 'IAH3', 'IAH3 ', 'IAH4', 'IAH4 ', 'IAI1', 'IAI2', 'IAI3', 'IAI4', 'IAu2', 'IAu3', 'ILH1', 'ILH2', 'ILI1', 'INH1', 'INI1', 'KSH1', 'KSH2', 'KSH3', 'KSI1', 'MIH1', 'MNH1', 'MNI1', 'MNI2', 'MNu1', 'MOH1', 'MOH1 ', 'MOH1-Rep1', 'MOH1-Rep2', 'MOH2', 'MOI1', 'MOI2', 'MOI3', 'NC1', 'NCH1', 'NCI1', 'NEH1', 'NEH2', 'NEH3', 'NEH4', 'NEI1', 'NYH1', 'NYH1', 'NYH2', 'NYH3', 'NYH4', 'NYI1', 'NYI2', 'NYS1', 'NYu', 'OHH1', 'ONH1', 'ONH2', 'PAI1', 'PAI2', 'SCH1', 'SDH1', 'SDI1', 'TX3', 'TXH1', 'TXH1-Dry', 'TXH1-Early', 'TXH1-Late', 'TXH2', 'TXH3', 'TXH4', 'TXI1', 'TXI2', 'TXI3', 'W1H1', 'W1H2', 'WIH1', 'WIH2', 'WIH3', 'WII1', 'WII2']\n"
     ]
    }
   ],
   "source": [
    "# confirm everything's okay\n",
    "print(\n",
    "  'meta', find_unrecognized_experiments(meta.Experiment_Code, return_all_exps=False), \n",
    "'\\nphno', find_unrecognized_experiments(phno.Experiment_Code, return_all_exps=False),\n",
    "'\\nsoil', find_unrecognized_experiments(soil.Experiment_Code, return_all_exps=False),\n",
    "'\\nwthr', find_unrecognized_experiments(wthr.Experiment_Code, return_all_exps=False),\n",
    "'\\nmgmt', find_unrecognized_experiments(mgmt.Experiment_Code, return_all_exps=False),\n",
    "'\\nall ', find_unrecognized_experiments([], return_all_exps=True)\n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94761eb",
   "metadata": {},
   "source": [
    "# Rearrange columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7387bad",
   "metadata": {},
   "source": [
    "## Process and reshape fertilizer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbb573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frustratingly `Fertilizer_Product` is only partially redundant. For some it contains information on amount \n",
    "# What I want to do is to keep `Fertilizer_Product` as `Product` but add an ingredient column to capture the npk data\n",
    "\n",
    "# 1. create a single schema to parse\n",
    "# 2. parse and merge into the desired table\n",
    "\n",
    "temp = meta.loc[:, [ 'Experiment_Code',\n",
    " 'N_Unit_lbs_per_A',\n",
    " 'P_Unit_lbs_per_A',\n",
    " 'K_Unit_lbs_per_A',\n",
    " 'Fertilizer_Product',\n",
    " 'Fertilizer_Application_Datetime_1',\n",
    " 'Fertilizer_Application_Datetime_2',\n",
    " 'Fertilizer_Application_Datetime_3',\n",
    " 'Fertilizer_Application_Datetime_4',\n",
    " 'Fertilizer_Application_Datetime_5',\n",
    " 'Fertilizer_Application_Datetime_6',\n",
    " 'Fertilizer_Application_Datetime_7',\n",
    " 'Fertilizer_Application_Datetime_8'\n",
    "                   ]]\n",
    "\n",
    "for e in ['N_Unit_lbs_per_A',\n",
    " 'P_Unit_lbs_per_A',\n",
    " 'K_Unit_lbs_per_A',\n",
    " 'Fertilizer_Product']:\n",
    "    temp.loc[temp[e].isna(), e]=0\n",
    "    temp[e] = temp[e].astype('string')\n",
    "    \n",
    "    \n",
    "temp.loc[:, 'Fertilizer_info'] = temp.loc[:, 'N_Unit_lbs_per_A']+' (N) '+temp.loc[:, 'P_Unit_lbs_per_A']+' (P) '+temp.loc[:, 'K_Unit_lbs_per_A']+' (K) '+' ['+temp.loc[:, 'Fertilizer_Product']+']'\n",
    "temp = temp.drop(columns= ['N_Unit_lbs_per_A',\n",
    "                          'P_Unit_lbs_per_A',\n",
    "                          'K_Unit_lbs_per_A',\n",
    "                          'Fertilizer_Product'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7c2542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not done here but this site has within field variation in management, so it would be best to resolve or drop it.\n",
    "# PAI2\n",
    "# '0 (N) 0 (P) 0 (K)  [urea; applied to south half  (Hi-N side) of field only]'\n",
    "# PAI1\n",
    "# '130 (N) 0 (P) 0 (K)  [urea (46-0-0); applied to south half (1/2 Acre, Hi-N side) of field only: actual applied was 140 lb urea to the Hi-N side of the field]'\n",
    "\n",
    "\n",
    "# safe create imputation notes\n",
    "temp = safe_create_col(temp, \"Imputation_Notes\")\n",
    "\n",
    "\n",
    "mask = temp.Fertilizer_info == '234 (N) 98 (P) 51 (K)  [Pre Plant incorporated 162# DAP & 85# potash dry spread; Planter 2x2 liquid starter 25#N & 24#P; Sidedress 180#N liquid 28% ]'\n",
    "temp.loc[mask, ['Fertilizer_info', 'Imputation_Notes']] = ['234 (N) 98 (P) 51 (K)', 'PrePlant']\n",
    "\n",
    "mask = temp.Fertilizer_info == '120lbs/acre in UAN applied prior to spring tillage. (N) 0 (P) 80 (K)  [UAN, potash]'\n",
    "temp = temp.loc[~mask, :]\n",
    "temp = temp.merge(pd.DataFrame(\n",
    "{'Experiment_Code': ['IAI3', 'IAI3'],\n",
    "'Fertilizer_Application_Datetime_1': ['4/16/15', '4/22/15'],\n",
    "'Fertilizer_info': ['120 (N)', '80 (K)']\n",
    "}\n",
    "), how = 'outer')\n",
    "\n",
    "# '150 lbs/acre in UAN form applied with chemical ahead of tillage (N) 18-60-120-15-1.5 (n-p-k-sulfur-zinc) (P) 120lbs, fall applied (K)  [Uan, MESZ, and Potash]'\n",
    "# unclear how much 18-60-120-15-1.5 (n-p-k-sulfur-zinc) was applied. Left as missing.\n",
    "mask = temp.Fertilizer_info == '150 lbs/acre in UAN form applied with chemical ahead of tillage (N) 18-60-120-15-1.5 (n-p-k-sulfur-zinc) (P) 120lbs, fall applied (K)  [Uan, MESZ, and Potash]'\n",
    "temp = temp.loc[~mask, :]\n",
    "temp = temp.merge(pd.DataFrame(\n",
    "{'Experiment_Code': ['IAI4', 'IAI4', 'IAI4', 'IAI4', 'IAI4', 'IAI4'],\n",
    "'Fertilizer_Application_Datetime_1': ['11/20/14', '5/3/15', '5/3/15', '5/3/15', '5/3/15', '5/3/15'],\n",
    "'Fertilizer_info': ['120 (K)', '150 (N)', '9999 (P)', '9999 (K)', '9999 (S)', '9999 (Zn)'] \n",
    "}\n",
    "), how = 'outer')\n",
    "\n",
    "mask = temp.Fertilizer_info == '167 (N) 80 (P) 60 (K)  [only total given by producer;  fall application of 17-80-60;  150 lbs. N in spring]'\n",
    "temp = temp.loc[~mask, :]\n",
    "temp = temp.merge(pd.DataFrame(\n",
    "{'Experiment_Code': ['IAH3', 'IAH3', 'IAH3', 'IAH3'],\n",
    "'Fertilizer_Application_Datetime_1': ['11/20/14', '11/20/14', '11/20/14', '5/3/15'],\n",
    "'Fertilizer_info': ['17 (N)', '80 (P)', '60 (K)', '150 (N)'] \n",
    "}\n",
    "), how = 'outer')     \n",
    "\n",
    "\n",
    "temp = sanitize_col(\n",
    "    df = temp, \n",
    "    col = 'Fertilizer_info', \n",
    "    simple_renames= {\n",
    "    '166 (N) 30 (P) 40 (K)  [first app. 11-52-9 map (6 lbs N, 30 lbs. P) + 0-0-60 granular potash, spring app of 150 lbs. N as NH3]': '150 (N)',\n",
    "    '200 (N) 0 (P) 0 (K)  [granular ammonium sulfate]': '200 (N)',\n",
    "    '118 (N) 0 (P) 0 (K)  [UAN; 32-0-0]': '118 (N)',\n",
    "    '180 (N) 0 (P) 0 (K)  [0.28]': '180 (N)',        \n",
    "    '180 (N) 0 (P) 0 (K)  [NH3 + N-serve]': '180 (N)',\n",
    "    '100 (N) 0 (P) 0 (K)  [UAN (28-0-0)]': '100 (N)',\n",
    "    '0 (N) 0 (P) 0 (K)  [0]': '0 (N)',\n",
    "    '80 (N) 0 (P) 0 (K)  [28% UAN]': '80 (N)',\n",
    "    '160 (N) 0 (P) 0 (K)  [Anhydrous Ammonia]': '160 (N)',\n",
    "    '100 (N) 0 (P) 0 (K)  [Ammonium Nitrate 34-0-0]': '100 (N)',\n",
    "    '120 (N) 0 (P) 0 (K)  [0]': '120 (N)',\n",
    "    '200 (N) 0 (P) 0 (K)  [Granular Urea]': '200 (N)',\n",
    "    '100 (N) 0 (P) 0 (K)  [0]': '100 (N)'\n",
    "    }, \n",
    "    split_renames= {\n",
    "    '234 (N) 98 (P) 51 (K)': [\n",
    "        '234 (N)', \n",
    "        '98 (P)', \n",
    "        '51 (K)'],\n",
    "    '180 (N) 0 (P) 90 (K)  [10-0-30 24S]': [\n",
    "        '180 (N)',                           \n",
    "        '90 (K)',                       \n",
    "        '9999 (S)'],\n",
    "    '86 (N) 19 (P) 0 (K)  [32-0-0, 10-34-0]': [\n",
    "        '86 (N)', \n",
    "        '19 (P)'],\n",
    "    '196 (N) 92 (P) 120 (K)  [dry fertilizer + 160# Ammonia]': [\n",
    "        '196 (N)', \n",
    "        '92 (P)', \n",
    "        '120 (K)'],\n",
    "    '160 (N) 48 (P) 24 (K)  [Starter]': [\n",
    "        '160 (N)', \n",
    "        '48 (P)', \n",
    "        '24 (K)'],          \n",
    "    '155 (N) 50 (P) 100 (K)  [UAN 28% Dry PK]': [\n",
    "        '155 (N)', \n",
    "        '50 (P)', \n",
    "        '100 (K)'],        \n",
    "    '201 (N) 76 (P) 76 (K)  [19-19-19 without zinc & UAN 30% ]': [\n",
    "        '201 (N)', \n",
    "         '76 (P)', \n",
    "         '76 (K)'],\n",
    "    '138 (N) 46 (P) 62 (K)  [Diammonium phosphate, KCl, Super U (Urea)]': [\n",
    "        '138 (N)', \n",
    "        '46 (P)', \n",
    "        '62 (K)'],\n",
    "    '175 (N) 200 (P) 240 (K)  [granular 8-20-30, popup 10-34-0, liquid nitrogen 28-0-0-0.5]': [\n",
    "        '175 (N)',  \n",
    "        '200 (P)',  \n",
    "        '240 (K)'],\n",
    "    '102 (N) 40 (P) 40 (K)  [NPK and 30% UAN]': [\n",
    "        '102 (N)', \n",
    "        '40 (P)', \n",
    "        '40 (K)'],\n",
    "    '220 (N) 193 (P) 0 (K)  [11-37-0-5 zn, 32-0-0 UAN]': [\n",
    "        '220 (N)', \n",
    "        '193 (P)', \n",
    "        '26.08108108108108 (Zn)'],\n",
    "    '235 (N) 156 (P) 156 (K)  [10-20-20 & 19-19-19 with zink and UAN 30%]': [\n",
    "        '235 (N)', \n",
    "        '156 (P)', \n",
    "        '156 (K)', \n",
    "        '9999 (Zn)'],          \n",
    "    '275 (N) 200 (P) 240 (K)  [granular 8-20-30, popup 10-34-0, liquid nitrogen 28-0-0-0.5]': [\n",
    "        '275 (N)', \n",
    "        '200 (P)',\n",
    "        '240 (K)'],\n",
    "    '220 (N) 193 (P) 0 (K)  [11-37-0-5 zn, 32-0-0]': [\n",
    "        '220 (N)', \n",
    "        '193 (P)', \n",
    "        '26.08108108108108 (Zn)'], # solved for total Zn based on provided values\n",
    "    '210.8 (N) 47.4 (P) 142.2 (K)  [10-10-30, 24S]': [\n",
    "        '210.8 (N)', \n",
    "        '47.4 (P)', \n",
    "        '142.2 (K)'],\n",
    "    '250 (N) 0 (P) 120 (K)  [300 lb/A 7-0-40 pre-plant 12.5gal/A 10-20-0-1 at planting 65gal/A UAN sidedress]': [\n",
    "        '250 (N)',\n",
    "        '120 (K)']\n",
    "        \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038cf1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.loc[:, 'Product'] = np.nan\n",
    "temp.loc[:, 'Amount_Per_Acre'] = np.nan\n",
    "\n",
    "# assume each string is formated as 'val (key)'. `sanitize_col` should be used to enforce this.\n",
    "for e in ['19 (P)', '48 (P)', '51 (K)', '235 (N)', '80 (P)', '86 (N)', '9999 (S)', '102 (N)', '100 (K)', '156 (P)', '92 (P)', '220 (N)', '193 (P)', '9999 (K)', '76 (K)', '0 (N)', '180 (N)', '9999 (Zn)', '90 (K)', '24 (K)', '9999 (P)', '155 (N)', '250 (N)', '100 (N)', '62 (K)', '40 (K)', '234 (N)', '26.08108108108108 (Zn)', '156 (K)', '240 (K)', '98 (P)', '120 (N)', '196 (N)', '175 (N)', '50 (P)', '200 (P)', '46 (P)', '120 (K)', '80 (N)', '80 (K)', '76 (P)', '200 (N)', '150 (N)', '160 (N)', '138 (N)', '40 (P)', '118 (N)', '201 (N)', '142.2 (K)', '275 (N)', '47.4 (P)', '60 (K)', '210.8 (N)', '17 (N)']:\n",
    "    val = re.findall('^\\d+[.]*\\d*', e)[0]\n",
    "    key = re.findall('\\(.+\\)',      e)[0].replace('(', '').replace(')', '')\n",
    "    \n",
    "    mask = (temp['Fertilizer_info'] == e)\n",
    "    temp.loc[mask, 'Product'] = key\n",
    "    temp.loc[mask, 'Amount_Per_Acre'] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba880479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to long format, spread total values across n applications\n",
    "temp = pd.melt(temp, id_vars=['Experiment_Code', 'Fertilizer_info', 'Imputation_Notes', 'Product', 'Amount_Per_Acre'])\n",
    "\n",
    "temp = temp.rename(columns={e: 'Amount_Per_Acre', 'value': 'Date_Datetime'})\n",
    "temp = temp.loc[pd.Series.notna(temp.Date_Datetime), :]\n",
    "temp = temp.loc[temp.Amount_Per_Acre.notna(), :]\n",
    "# now that we have removed the nas that are likely 0 we can set the unknowns from 9999 to np.nan\n",
    "mask = (temp.Amount_Per_Acre == 9999)\n",
    "temp.loc[mask, 'Amount_Per_Acre'] = np.nan\n",
    "\n",
    "tally = temp.assign(n = 1).groupby('Experiment_Code').agg(n = ('n', np.sum)).reset_index()\n",
    "temp = temp.merge(tally)\n",
    "safe_create_col(temp, 'Unit')\n",
    "temp.loc[:, 'Unit'] = 'lbs/Acre'\n",
    "\n",
    "temp.Amount_Per_Acre = temp.Amount_Per_Acre.astype('float64')\n",
    "temp.Amount_Per_Acre = temp.Amount_Per_Acre/temp.n\n",
    "temp = temp.drop(columns= ['variable', 'n'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed19955",
   "metadata": {},
   "source": [
    "##  Move management columns from meta to mgmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eda453",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgmt = mgmt.merge(temp, how = 'outer'\n",
    "          ).merge(meta.loc[:, [\n",
    "           'Experiment_Code',\n",
    "           'Pre_Plant_Herbicide',\n",
    "           'Post_Plant_Herbicide',\n",
    "           'Insecticide']].drop_duplicates(), how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df75d14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = meta.drop(columns=[\n",
    "    'Pre_Plant_Herbicide',\n",
    "    'Post_Plant_Herbicide',\n",
    "    'Insecticide',\n",
    "    'N_Unit_lbs_per_A',\n",
    "    'P_Unit_lbs_per_A',\n",
    "    'K_Unit_lbs_per_A',\n",
    "    'Fertilizer_Product',\n",
    "    'Fertilizer_Application_Datetime_1',\n",
    "    'Fertilizer_Application_Datetime_2',\n",
    "    'Fertilizer_Application_Datetime_3',\n",
    "    'Fertilizer_Application_Datetime_4',\n",
    "    'Fertilizer_Application_Datetime_5',\n",
    "    'Fertilizer_Application_Datetime_6',\n",
    "    'Fertilizer_Application_Datetime_7',\n",
    "    'Fertilizer_Application_Datetime_8'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c8f91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate static and dynamic values\n",
    "sval = phno.merge(soil, how = 'outer')\n",
    "sval = sval.merge(meta.drop(columns='Test_Weight_Unit_lbs'), how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad04a392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these tables are different enought we'll keep them separate\n",
    "# mgmt\n",
    "# unfortunately we need multiples because at least one field treats different passes differently\n",
    "mgmt = phno.loc[:, ['Year', 'Experiment_Code', 'Range', 'Pass', 'Plot', 'phno']\n",
    "               ].drop_duplicates().merge(mgmt, how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e23bfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgmt = mgmt.loc[mgmt.mgmt.notna(), :].drop(columns = 'phno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4090cb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set each id col to a string\n",
    "for i in ['Year', 'Experiment_Code', 'Range', 'Pass', 'Plot']:\n",
    "    sval[i] = sval[i].astype('string')\n",
    "    mgmt[i]  =  mgmt[i].astype('string')\n",
    "    \n",
    "    if i not in ['Range', 'Pass', 'Plot']:\n",
    "        wthr[i]  =  wthr[i].astype('string')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a94f13",
   "metadata": {},
   "source": [
    "# Sanitize Non-ID columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcc8720",
   "metadata": {},
   "source": [
    "## Sanitization functions\n",
    "\n",
    "The pattern to use is:\n",
    " 1. Alter the dataframe\n",
    " 1. Test the dataframe against expectations\n",
    " \n",
    "The main tasks that need to be completed are:\n",
    " 1. Identify values that can't be converted to the expected data type. The \"find_unconvertable_\" family of functions should be used. \n",
    "     1. `find_unconvertable_datetimes`\n",
    "     \n",
    " 1. For simple renaming (e.g. misspellings) or splitting non-tidy data into two rows (\"entry1-entry2\" -> \"entry1\", \"entry2\") use `sanitize_col` \n",
    " 1. Move values that are ambigous but pertain to data imputation to \"Imputation_Notes\" using `relocate_to_Imputation_Notes`\n",
    " 1. If new columns need to be added (e.g. mgmt.Ingredient for parsed components of Product (e.g. elements) ) this should be accomplished with `safe_create_col`.\n",
    " 1. Any one off changes should be accomplised manually. \n",
    " 1. Confirm columns match the expected types with `check_df_dtype_expectations`, and report mismatches. \n",
    "\n",
    "\n",
    "These steps should be completed for each dataframe in turn to minimize the cognitive load of the reader. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cad031",
   "metadata": {},
   "source": [
    "## Sanitization: Column data type expectations\n",
    "Note: to handle missing values some columns that would otherwise be ints are floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40b6f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Experiment_Code</th>\n",
       "      <th>Range</th>\n",
       "      <th>Pass</th>\n",
       "      <th>Plot</th>\n",
       "      <th>Irrigation_Applied</th>\n",
       "      <th>Weather_Station_Documents_Irrigation</th>\n",
       "      <th>Application</th>\n",
       "      <th>Product</th>\n",
       "      <th>Date_Datetime</th>\n",
       "      <th>Amount_Per_Acre</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Nutrients_Applied</th>\n",
       "      <th>Management_Comments</th>\n",
       "      <th>mgmt</th>\n",
       "      <th>Fertilizer_info</th>\n",
       "      <th>Imputation_Notes</th>\n",
       "      <th>Pre_Plant_Herbicide</th>\n",
       "      <th>Post_Plant_Herbicide</th>\n",
       "      <th>Insecticide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>DEH1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>irrigation</td>\n",
       "      <td>water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>in/Acre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lexar 3qt/A combo of Metolachlor, Atrazine and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Force 3G 5.5 lb/A at planting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>DEH1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>irrigation</td>\n",
       "      <td>water</td>\n",
       "      <td>5/15/2015</td>\n",
       "      <td>0.5</td>\n",
       "      <td>in/Acre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lexar 3qt/A combo of Metolachlor, Atrazine and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Force 3G 5.5 lb/A at planting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>DEH1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>irrigation</td>\n",
       "      <td>water</td>\n",
       "      <td>5/28/2015</td>\n",
       "      <td>0.3</td>\n",
       "      <td>in/Acre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lexar 3qt/A combo of Metolachlor, Atrazine and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Force 3G 5.5 lb/A at planting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>DEH1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>irrigation</td>\n",
       "      <td>water</td>\n",
       "      <td>6/16/2015</td>\n",
       "      <td>0.8</td>\n",
       "      <td>in/Acre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lexar 3qt/A combo of Metolachlor, Atrazine and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Force 3G 5.5 lb/A at planting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015.0</td>\n",
       "      <td>DEH1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>irrigation</td>\n",
       "      <td>water</td>\n",
       "      <td>7/1/2015</td>\n",
       "      <td>0.3</td>\n",
       "      <td>in/Acre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lexar 3qt/A combo of Metolachlor, Atrazine and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Force 3G 5.5 lb/A at planting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59600</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>SDI1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59601</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>TXI2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.66 pts Dual; S-metolachlor, 1.5 lbs atrazine</td>\n",
       "      <td>Prowl H2O; pendamethaline, 1 lb Atrazine</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59611</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>TXI3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59612</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>WII1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tank Mix (Callisto, AI Mesotrione) (Dual 2 Mag...</td>\n",
       "      <td>Counter Force 3G (AI Tefluthrin)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59614</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>WII2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tank Mix (Callisto, AI Mesotrione) (Dual 2 Mag...</td>\n",
       "      <td>Counter Force 3G (AI Tefluthrin)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22777 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Year Experiment_Code Range  Pass  Plot Irrigation_Applied  \\\n",
       "0      2015.0            DEH1   2.0   1.0   1.0                Yes   \n",
       "1      2015.0            DEH1   2.0   1.0   1.0                Yes   \n",
       "2      2015.0            DEH1   2.0   1.0   1.0                Yes   \n",
       "3      2015.0            DEH1   2.0   1.0   1.0                Yes   \n",
       "4      2015.0            DEH1   2.0   1.0   1.0                Yes   \n",
       "...       ...             ...   ...   ...   ...                ...   \n",
       "59600    <NA>            SDI1  <NA>  <NA>  <NA>                 No   \n",
       "59601    <NA>            TXI2  <NA>  <NA>  <NA>                 No   \n",
       "59611    <NA>            TXI3  <NA>  <NA>  <NA>                 No   \n",
       "59612    <NA>            WII1  <NA>  <NA>  <NA>                 No   \n",
       "59614    <NA>            WII2  <NA>  <NA>  <NA>                 No   \n",
       "\n",
       "      Weather_Station_Documents_Irrigation Application Product Date_Datetime  \\\n",
       "0                                      Yes  irrigation   water           NaN   \n",
       "1                                      Yes  irrigation   water     5/15/2015   \n",
       "2                                      Yes  irrigation   water     5/28/2015   \n",
       "3                                      Yes  irrigation   water     6/16/2015   \n",
       "4                                      Yes  irrigation   water      7/1/2015   \n",
       "...                                    ...         ...     ...           ...   \n",
       "59600                                   No         NaN     NaN           NaN   \n",
       "59601                                   No         NaN     NaN           NaN   \n",
       "59611                                   No         NaN     NaN           NaN   \n",
       "59612                                   No         NaN     NaN           NaN   \n",
       "59614                                   No         NaN     NaN           NaN   \n",
       "\n",
       "       Amount_Per_Acre     Unit  Nutrients_Applied Management_Comments  mgmt  \\\n",
       "0                  NaN  in/Acre                NaN                 NaN  True   \n",
       "1                  0.5  in/Acre                NaN                 NaN  True   \n",
       "2                  0.3  in/Acre                NaN                 NaN  True   \n",
       "3                  0.8  in/Acre                NaN                 NaN  True   \n",
       "4                  0.3  in/Acre                NaN                 NaN  True   \n",
       "...                ...      ...                ...                 ...   ...   \n",
       "59600              NaN      NaN                NaN                 NaN  True   \n",
       "59601              NaN      NaN                NaN                 NaN  True   \n",
       "59611              NaN      NaN                NaN                 NaN  True   \n",
       "59612              NaN      NaN                NaN                 NaN  True   \n",
       "59614              NaN      NaN                NaN                 NaN  True   \n",
       "\n",
       "      Fertilizer_info Imputation_Notes  \\\n",
       "0                 NaN              NaN   \n",
       "1                 NaN              NaN   \n",
       "2                 NaN              NaN   \n",
       "3                 NaN              NaN   \n",
       "4                 NaN              NaN   \n",
       "...               ...              ...   \n",
       "59600             NaN              NaN   \n",
       "59601             NaN              NaN   \n",
       "59611             NaN              NaN   \n",
       "59612             NaN              NaN   \n",
       "59614             NaN              NaN   \n",
       "\n",
       "                                     Pre_Plant_Herbicide  \\\n",
       "0      Lexar 3qt/A combo of Metolachlor, Atrazine and...   \n",
       "1      Lexar 3qt/A combo of Metolachlor, Atrazine and...   \n",
       "2      Lexar 3qt/A combo of Metolachlor, Atrazine and...   \n",
       "3      Lexar 3qt/A combo of Metolachlor, Atrazine and...   \n",
       "4      Lexar 3qt/A combo of Metolachlor, Atrazine and...   \n",
       "...                                                  ...   \n",
       "59600                                                NaN   \n",
       "59601     1.66 pts Dual; S-metolachlor, 1.5 lbs atrazine   \n",
       "59611                                                NaN   \n",
       "59612                                                NaN   \n",
       "59614                                                NaN   \n",
       "\n",
       "                                    Post_Plant_Herbicide  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "59600                                                NaN   \n",
       "59601           Prowl H2O; pendamethaline, 1 lb Atrazine   \n",
       "59611                                                NaN   \n",
       "59612  Tank Mix (Callisto, AI Mesotrione) (Dual 2 Mag...   \n",
       "59614  Tank Mix (Callisto, AI Mesotrione) (Dual 2 Mag...   \n",
       "\n",
       "                            Insecticide  \n",
       "0         Force 3G 5.5 lb/A at planting  \n",
       "1         Force 3G 5.5 lb/A at planting  \n",
       "2         Force 3G 5.5 lb/A at planting  \n",
       "3         Force 3G 5.5 lb/A at planting  \n",
       "4         Force 3G 5.5 lb/A at planting  \n",
       "...                                 ...  \n",
       "59600                               NaN  \n",
       "59601                               NaN  \n",
       "59611                               NaN  \n",
       "59612  Counter Force 3G (AI Tefluthrin)  \n",
       "59614  Counter Force 3G (AI Tefluthrin)  \n",
       "\n",
       "[22777 rows x 20 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sval_col_dtypes = mk_dtype_dict(name = 'sval')\n",
    "wthr_col_dtypes = mk_dtype_dict(name = 'wthr')\n",
    "mgmt_col_dtypes = mk_dtype_dict(name = 'mgmt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972cfb9f",
   "metadata": {},
   "source": [
    "# Sanitization: Alter entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccee17b",
   "metadata": {},
   "source": [
    "## Static values (within season)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ab9954",
   "metadata": {},
   "source": [
    "### Datetime containing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a74ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sval.loc[sval.Recieved_Date_Unit_Datetime == 'See Soil Sample', 'Recieved_Date_Unit_Datetime'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d2d163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planted_Unit_Datetime\n",
      "Harvested_Unit_Datetime\n",
      "Anthesis_Unit_Datetime\n",
      "Silking_Unit_Datetime\n",
      "Recieved_Date_Unit_Datetime\n",
      "Weather_Station_Placed_Unit_Datetime\n",
      "Weather_Station_Removed_Unit_Datetime\n"
     ]
    }
   ],
   "source": [
    "# convert the date cols into datetime. Lean on pd.to_datetime() to infer the format, assume that each site uses the same format.\n",
    "\n",
    "for e in ['Planted_Unit_Datetime', \n",
    "    'Harvested_Unit_Datetime', \n",
    "    'Anthesis_Unit_Datetime', \n",
    "    'Silking_Unit_Datetime', \n",
    "    'Recieved_Date_Unit_Datetime', \n",
    "#     'Processed_Date_Unit_Datetime', \n",
    "    'Weather_Station_Placed_Unit_Datetime', \n",
    "    'Weather_Station_Removed_Unit_Datetime'\n",
    "    ]:\n",
    "# find_unconvertable_datetimes(df_col=sval[e], pattern='%Y-%m-%d %H:%M', index=False)\n",
    "\n",
    "    sval['Datetime_Temp'] = pd.to_datetime(np.nan)\n",
    "    print(e)\n",
    "    for code in list(sval.Experiment_Code.drop_duplicates()):\n",
    "\n",
    "    # code = list(sval.Experiment_Code.drop_duplicates())[0]\n",
    "        sval.loc[sval.Experiment_Code == code, 'Datetime_Temp'\n",
    "                 ] = pd.to_datetime(sval.loc[sval.Experiment_Code == code, e])\n",
    "\n",
    "    sval.loc[:, e] = sval.loc[:, 'Datetime_Temp'] \n",
    "\n",
    "sval = sval.drop(columns = 'Datetime_Temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826b9321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to bool\n",
    "sval = sanitize_col(\n",
    "    df = sval, \n",
    "    col = 'Discarded', \n",
    "    simple_renames= {\n",
    "        'Yes':'True',\n",
    "        'yes':'True'}, \n",
    "    split_renames= {})\n",
    "\n",
    "# set missing to false\n",
    "sval.loc[sval.Discarded.isna(), 'Discarded'] = 'False'\n",
    "sval.Discarded = sval.Discarded.map({'True': True, 'False': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e4df11",
   "metadata": {},
   "source": [
    "### Simple Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6927f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to float\n",
    "# # sval.Pounds_Needed_Soil_Moisture.astype(float)\n",
    "sval = sval.drop(columns=['Drop_Record_Index', 'Additional_Metics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9768e7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to bool\n",
    "sval['phno'] = sval['phno'].astype('bool')\n",
    "sval['soil'] = sval['soil'].astype('bool')\n",
    "sval['meta'] = sval['meta'].astype('bool')\n",
    "\n",
    "# to string\n",
    "sval = cols_astype_string(\n",
    "    df = sval, \n",
    "    col_list = [key for key in sval_col_dtypes.keys() if sval_col_dtypes[key] == 'string'])\n",
    "\n",
    "sval.Year = year_string\n",
    "sval.Year = sval.Year.astype('string')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55b1261",
   "metadata": {},
   "source": [
    "### Check Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec742610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 Columns pass.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = check_df_dtype_expectations(df = sval, dtype_dct = sval_col_dtypes)\n",
    "\n",
    "if sum(checkpoint.Pass)/checkpoint.shape[0] == 1:\n",
    "    pass\n",
    "else:\n",
    "    print(checkpoint.loc[~checkpoint.Pass, ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54014602",
   "metadata": {},
   "source": [
    "## Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af31085f",
   "metadata": {},
   "source": [
    "### Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1946e1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... or we use the fields in the df to make a consistent format\n",
    "wthr = cols_astype_string(\n",
    "    df = wthr, \n",
    "    col_list = ['Year', 'Month', 'Day', 'Time'])\n",
    "\n",
    "wthr['Datetime_Temp'] = wthr['Year']+'-'+wthr['Month']+'-'+wthr['Day']+' '+wthr['Time']\n",
    "\n",
    "wthr['Datetime'] = pd.to_datetime(pd.Series(wthr.Datetime_Temp))\n",
    "wthr = wthr.drop(columns= 'Datetime_Temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071988b1",
   "metadata": {},
   "source": [
    "### Photoperiod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83f11c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = wthr.Photoperiod_Unit_Hours.notna()\n",
    "temp = wthr.Photoperiod_Unit_Hours.str.split(\":\", expand=True)\n",
    "wthr.Photoperiod_Unit_Hours = temp.loc[:, 0].astype(float) + (temp.loc[:, 1].astype(float)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929ff016",
   "metadata": {},
   "source": [
    "### Data_Cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fc5d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to bool\n",
    "wthr = sanitize_col(\n",
    "    df = wthr, \n",
    "    col = 'Data_Cleaned', \n",
    "    simple_renames= {\n",
    "        'Yes':'True',\n",
    "        'No':'False'}, \n",
    "    split_renames= {})\n",
    "\n",
    "# set missing to false\n",
    "wthr.loc[wthr.Data_Cleaned.isna(), 'Data_Cleaned'] = 'False'\n",
    "wthr.Data_Cleaned = wthr.Data_Cleaned.map({'True': True, 'False': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ccd74b",
   "metadata": {},
   "source": [
    "### Simple Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732c3010",
   "metadata": {},
   "outputs": [],
   "source": [
    "wthr = wthr.drop(columns=['Drop_Record_Index',\n",
    "                         'CO2_Unit_ppm' # 0 non null\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed990b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to string\n",
    "wthr = cols_astype_string(\n",
    "    df = wthr, \n",
    "    col_list = [key for key in wthr_col_dtypes.keys() if wthr_col_dtypes[key] == 'string'])\n",
    "\n",
    "wthr.Year = year_string\n",
    "wthr.Year = wthr.Year.astype('string')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801ad550",
   "metadata": {},
   "source": [
    "### Check Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53fd6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 Columns pass.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = check_df_dtype_expectations(df = wthr, dtype_dct = wthr_col_dtypes)\n",
    "\n",
    "if sum(checkpoint.Pass)/checkpoint.shape[0] == 1:\n",
    "    pass\n",
    "else:\n",
    "    print(checkpoint.loc[~checkpoint.Pass, ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1958033e",
   "metadata": {},
   "source": [
    "## Management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcf1a42",
   "metadata": {},
   "source": [
    "### Date_Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b612643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert types\n",
    "err_list = find_unconvertable_datetimes(df_col=mgmt.Date_Datetime, pattern='%m/%d/%Y', index=False)\n",
    "if err_list != []:\n",
    "    print(err_list)\n",
    "else:\n",
    "    mgmt.Date_Datetime = pd.to_datetime(pd.Series(mgmt.Date_Datetime), format = '%m/%d/%Y', errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497e0f42",
   "metadata": {},
   "source": [
    "### Amount_Per_Acre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06e476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# effectively done above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc11303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert types\n",
    "err_list = find_unconvertable_numerics(df_col = mgmt['Amount_Per_Acre'], index = False)\n",
    "if err_list != []:\n",
    "    print(err_list)\n",
    "else:\n",
    "    mgmt.Amount_Per_Acre = pd.to_numeric(mgmt.Amount_Per_Acre, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57973e80",
   "metadata": {},
   "source": [
    "### Ingredient\n",
    "This is to be the cleaned up version of the \"Product\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66140777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(mgmt.loc[:, 'Ingredient'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829c3e99",
   "metadata": {},
   "source": [
    "### Simple Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb60d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to bool\n",
    "mgmt['mgmt'] = mgmt['mgmt'].astype('bool')\n",
    "\n",
    "# to string\n",
    "for e in [ee for ee in ['Irrigation_Applied', 'Weather_Station_Documents_Irrigation', 'Application', 'Product', 'Unit', 'Nutrients_Applied', 'Management_Comments', 'Fertilizer_info', 'Imputation_Notes', 'Pre_Plant_Herbicide', 'Post_Plant_Herbicide', 'Insecticide'] if ee in mgmt.columns]:\n",
    "    mgmt[e] = mgmt[e].astype('string')\n",
    "    \n",
    "\n",
    "mgmt.Year = year_string\n",
    "mgmt.Year = mgmt.Year.astype('string')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b2160e",
   "metadata": {},
   "source": [
    "### Check Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1578ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 Columns pass.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = check_df_dtype_expectations(df = mgmt, dtype_dct = mgmt_col_dtypes)\n",
    "\n",
    "if sum(checkpoint.Pass)/checkpoint.shape[0] == 1:\n",
    "    pass\n",
    "else:\n",
    "    print(checkpoint.loc[~checkpoint.Pass, ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3109ee8b",
   "metadata": {},
   "source": [
    "# Publish\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf01fde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_out_pkl(obj = sval, path = './data/interim/'+year_string+'sval.pickle')\n",
    "write_out_pkl(obj = wthr, path = './data/interim/'+year_string+'wthr.pickle')\n",
    "write_out_pkl(obj = mgmt, path = './data/interim/'+year_string+'mgmt.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
