{
 "cells": [
  {
   "cell_type": "raw",
   "id": "2164ebf9",
   "metadata": {},
   "source": [
    "---\n",
    "description: This notebook brings the 2020 into alignment with the desired format\n",
    "  with respect to field name, type, and grouping.\n",
    "output-file: freshstart_2020.html\n",
    "title: Process Data from 2020 into a consistent format.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9bf5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports ----\n",
    "import re\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59a6757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from g2fd.internal import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a5bc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp internal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1692f5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020\n",
    "year_string = '2020'\n",
    "\n",
    "meta_path = './data/raw/GenomesToFields_G2F_data_2020/z._2020_supplemental_info/g2f_2020_field_metadata.csv'\n",
    "phno_path = './data/raw/GenomesToFields_G2F_data_2020/a._2020_phenotypic_data/g2f_2020_phenotypic_clean_data.csv' \n",
    "wthr_path = './data/raw/GenomesToFields_G2F_data_2020/b._2020_weather_data/2020_weather_cleaned.csv'\n",
    "soil_path = './data/raw/GenomesToFields_G2F_data_2020/c._2020_soil_data/g2f_2020_soil_data.csv'\n",
    "mgmt_path = './data/raw/GenomesToFields_G2F_data_2020/z._2020_supplemental_info/g2f_2020_agronomic_information.csv'\n",
    "\n",
    "meta = pd.read_csv(meta_path, encoding = \"ISO-8859-1\", low_memory=False)\n",
    "phno = pd.read_csv(phno_path, encoding = \"ISO-8859-1\", low_memory=False)\n",
    "wthr = pd.read_csv(wthr_path, encoding = \"ISO-8859-1\", low_memory=False)\n",
    "soil = pd.read_csv(soil_path, encoding = \"ISO-8859-1\", low_memory=False)\n",
    "mgmt = pd.read_csv(mgmt_path, encoding = \"ISO-8859-1\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba20000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dicts for column renaming\n",
    "meta_name_dict = mk_name_dict(name = 'meta')\n",
    "phno_name_dict = mk_name_dict(name = 'phno')\n",
    "soil_name_dict = mk_name_dict(name = 'soil')\n",
    "wthr_name_dict = mk_name_dict(name = 'wthr')\n",
    "mgmt_name_dict = mk_name_dict(name = 'mgmt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1ab577",
   "metadata": {},
   "source": [
    "# Rename\n",
    "**Naming rules:**\n",
    "- One dict for each input df\n",
    "- Comment out anything that shouldn't be changed\n",
    "- Upper_Upper_Unit_\\$unit\n",
    "- Upper_$number\n",
    "- No special characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e46916d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [], [], [], [])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(find_unrecognized_columns(df = meta, dct = meta_name_dict),\n",
    "find_unrecognized_columns(df = phno, dct = phno_name_dict),\n",
    "find_unrecognized_columns(df = soil, dct = soil_name_dict),\n",
    "find_unrecognized_columns(df = wthr, dct = wthr_name_dict),\n",
    "find_unrecognized_columns(df = mgmt, dct = mgmt_name_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9080f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = meta.rename(columns=meta_name_dict)\n",
    "phno = phno.rename(columns=phno_name_dict)\n",
    "soil = soil.rename(columns=soil_name_dict)\n",
    "wthr = wthr.rename(columns=wthr_name_dict)\n",
    "mgmt = mgmt.rename(columns=mgmt_name_dict)\n",
    "\n",
    "# add indicator columns to help with debugging merge\n",
    "meta['meta'] = True\n",
    "phno['phno'] = True\n",
    "soil['soil'] = True\n",
    "wthr['wthr'] = True\n",
    "mgmt['mgmt'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485b4fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(26, 55), (18754, 41), (23, 30), (289867, 24), (142, 7)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e.shape for e in [meta, phno, soil, wthr, mgmt]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1589ac0",
   "metadata": {},
   "source": [
    "# Sanatize ID columns as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca242c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wthr = sanitize_Experiment_Codes(\n",
    "    df = wthr, \n",
    "    simple_renames = {\n",
    "    }, \n",
    "    split_renames = {\n",
    "        'NYH3_NYS1': ['NYS1', 'NYH3'],\n",
    "        'TXH1_TXH3': ['TXH1', 'TXH3']\n",
    "    })\n",
    "\n",
    "# for some reason there are 2227 empty rows included...\n",
    "wthr = wthr.loc[wthr.Experiment_Code.notna(), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864c852a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta [] \n",
      "phno [] \n",
      "soil [] \n",
      "wthr [] \n",
      "mgmt [] \n",
      "all  ['COH1', 'DEH1', 'GAH1', 'GAH2', 'GEH1', 'IAH1', 'IAH2', 'IAH3', 'IAH4', 'ILH1', 'INH1', 'MIH1', 'MNH1', 'MOH1', 'NCH1', 'NEH1', 'NEH2', 'NEH3', 'NYH2', 'NYH3', 'NYS1', 'OHH1', 'SCH1', 'TXH1', 'TXH2', 'TXH3', 'WIH1', 'WIH2', 'WIH3']\n"
     ]
    }
   ],
   "source": [
    "# confirm everything's okay\n",
    "print(\n",
    "  'meta', find_unrecognized_experiments(meta.Experiment_Code, return_all_exps=False), \n",
    "'\\nphno', find_unrecognized_experiments(phno.Experiment_Code, return_all_exps=False),\n",
    "'\\nsoil', find_unrecognized_experiments(soil.Experiment_Code, return_all_exps=False),\n",
    "'\\nwthr', find_unrecognized_experiments(wthr.Experiment_Code, return_all_exps=False),\n",
    "'\\nmgmt', find_unrecognized_experiments(mgmt.Experiment_Code, return_all_exps=False),\n",
    "'\\nall ', find_unrecognized_experiments([], return_all_exps=True)\n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94761eb",
   "metadata": {},
   "source": [
    "# Rearrange columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb762bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate static and dynamic values\n",
    "sval = phno.merge(soil, how = 'outer')\n",
    "sval = sval.merge(meta, how = 'outer') # This introduces 3 sites that have no data\n",
    "# sval.shape # used to confirm nrow = #20574 + 3\n",
    "\n",
    "# these tables are different enought we'll keep them separate\n",
    "# mgmt\n",
    "# unfortunately we need multiples because at least one field treats different passes differently\n",
    "mgmt = phno.loc[:, ['Year', 'Experiment_Code', 'Range', 'Pass', 'Plot', 'phno']\n",
    "               ].drop_duplicates().merge(mgmt, how = 'outer')\n",
    "# confirm there are no rows in mgmt that are not in phno\n",
    "temp = mgmt.loc[(~mgmt.phno & mgmt.mgmt), :]\n",
    "if 0 != temp.shape[0]:\n",
    "    print(temp)\n",
    "else:\n",
    "    mgmt = mgmt.loc[mgmt.mgmt.notna(), :].drop(columns = 'phno')\n",
    "\n",
    "\n",
    "# wthr\n",
    "# There's only ever one weather station so we have to worry about imputation but not duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4090cb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set each id col to a string\n",
    "for i in ['Year', 'Experiment_Code', 'Range', 'Pass', 'Plot']:\n",
    "    sval[i] = sval[i].astype('string')\n",
    "    mgmt[i]  =  mgmt[i].astype('string')\n",
    "    \n",
    "    if i not in ['Range', 'Pass', 'Plot']:\n",
    "        wthr[i]  =  wthr[i].astype('string')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a94f13",
   "metadata": {},
   "source": [
    "# Sanitize Non-ID columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcc8720",
   "metadata": {},
   "source": [
    "## Sanitization functions\n",
    "\n",
    "The pattern to use is:\n",
    " 1. Alter the dataframe\n",
    " 1. Test the dataframe against expectations\n",
    " \n",
    "The main tasks that need to be completed are:\n",
    " 1. Identify values that can't be converted to the expected data type. The \"find_unconvertable_\" family of functions should be used. \n",
    "     1. `find_unconvertable_datetimes`\n",
    "     \n",
    " 1. For simple renaming (e.g. misspellings) or splitting non-tidy data into two rows (\"entry1-entry2\" -> \"entry1\", \"entry2\") use `sanitize_col` \n",
    " 1. Move values that are ambigous but pertain to data imputation to \"Imputation_Notes\" using `relocate_to_Imputation_Notes`\n",
    " 1. If new columns need to be added (e.g. mgmt.Ingredient for parsed components of Product (e.g. elements) ) this should be accomplished with `safe_create_col`.\n",
    " 1. Any one off changes should be accomplised manually. \n",
    " 1. Confirm columns match the expected types with `check_df_dtype_expectations`, and report mismatches. \n",
    "\n",
    "\n",
    "These steps should be completed for each dataframe in turn to minimize the cognitive load of the reader. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cad031",
   "metadata": {},
   "source": [
    "## Sanitization: Column data type expectations\n",
    "Note: to handle missing values some columns that would otherwise be ints are floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6b17d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sval_col_dtypes = mk_dtype_dict(name = 'sval')\n",
    "wthr_col_dtypes = mk_dtype_dict(name = 'wthr')\n",
    "mgmt_col_dtypes = mk_dtype_dict(name = 'mgmt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972cfb9f",
   "metadata": {},
   "source": [
    "# Sanitization: Alter entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccee17b",
   "metadata": {},
   "source": [
    "## Static values (within season)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fa13b3",
   "metadata": {},
   "source": [
    "### Datetime containing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd9e46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the date cols into datetime. Lean on pd.to_datetime() to infer the format, assume that each site uses the same format.\n",
    "\n",
    "for e in ['Planted_Unit_Datetime', \n",
    "    'Harvested_Unit_Datetime', \n",
    "    'Anthesis_Unit_Datetime', \n",
    "    'Silking_Unit_Datetime', \n",
    "    'Recieved_Date_Unit_Datetime', \n",
    "    'Processed_Date_Unit_Datetime', \n",
    "    'Weather_Station_Placed_Unit_Datetime', \n",
    "    'Weather_Station_Removed_Unit_Datetime'\n",
    "    ]:\n",
    "\n",
    "    sval['Datetime_Temp'] = pd.to_datetime(np.nan)\n",
    "\n",
    "    for code in list(sval.Experiment_Code.drop_duplicates()):\n",
    "    # code = list(sval.Experiment_Code.drop_duplicates())[0]\n",
    "        sval.loc[sval.Experiment_Code == code, 'Datetime_Temp'\n",
    "                 ] = pd.to_datetime(sval.loc[sval.Experiment_Code == code, e])\n",
    "\n",
    "    sval.loc[:, e] = sval.loc[:, 'Datetime_Temp'] \n",
    "\n",
    "sval = sval.drop(columns = 'Datetime_Temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da16560b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba2b1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert types\n",
    "for e in ['Alley_Length_Unit_Inches', 'Row_Spacing_Unit_Inches', 'Pounds_Needed_Soil_Moisture',\n",
    "         'Anthesis_Unit_Days', 'Silking_Unit_Days', 'Kernels_Per_Plot']:\n",
    "    err_list = find_unconvertable_numerics(df_col = sval[e], index = False)\n",
    "    if err_list != []:\n",
    "        print(e)\n",
    "        print(err_list)\n",
    "    else:\n",
    "        sval[e] = sval[e].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116641a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to bool\n",
    "sval = sanitize_col(\n",
    "    df = sval, \n",
    "    col = 'Discarded', \n",
    "    simple_renames= {\n",
    "        'Yes':'True',\n",
    "        'yes':'True'}, \n",
    "    split_renames= {})\n",
    "\n",
    "# set missing to false\n",
    "sval.loc[sval.Discarded.isna(), 'Discarded'] = 'False'\n",
    "sval.Discarded = sval.Discarded.map({'True': True, 'False': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cab2a21",
   "metadata": {},
   "source": [
    "### Simple Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd483988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to bool\n",
    "sval['phno'] = sval['phno'].astype('bool')\n",
    "sval['soil'] = sval['soil'].astype('bool')\n",
    "sval['meta'] = sval['meta'].astype('bool')\n",
    "\n",
    "# to string\n",
    "sval = cols_astype_string(\n",
    "    df = sval, \n",
    "    col_list = [key for key in sval_col_dtypes.keys() if sval_col_dtypes[key] == 'string'])\n",
    "\n",
    "sval.Year = year_string\n",
    "sval.Year = sval.Year.astype('string')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497187da",
   "metadata": {},
   "source": [
    "### Check Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec742610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 Columns pass.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = check_df_dtype_expectations(df = sval, dtype_dct = sval_col_dtypes)\n",
    "\n",
    "if sum(checkpoint.Pass)/checkpoint.shape[0] == 1:\n",
    "    pass\n",
    "else:\n",
    "    print(checkpoint.loc[~checkpoint.Pass, ]) #TODO add to template\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54014602",
   "metadata": {},
   "source": [
    "## Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3857130",
   "metadata": {},
   "source": [
    "### Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b0fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 183 records from MNH1 are missing a value for time. \n",
    "# These are not useful since we don't know if the values are daily averages or taken at a specific timepoint.\n",
    "wthr = wthr.loc[wthr.Time.notna(), :]\n",
    "\n",
    "# unfortunately these missing values also force ints (e.g. days) to be floats\n",
    "wthr.Year = wthr.Year.astype(float).astype(int).astype('string')\n",
    "wthr.Month = wthr.Month.astype(float).astype(int).astype('string')\n",
    "wthr.Day = wthr.Day.astype(float).astype(int).astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5c9e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the fields in the df to make a consistent format\n",
    "wthr = cols_astype_string(\n",
    "    df = wthr, \n",
    "    col_list = ['Year', 'Month', 'Day', 'Time'])\n",
    "\n",
    "wthr = sanitize_col(\n",
    "    df = wthr,\n",
    "    col = 'Time', \n",
    "    simple_renames= {}, \n",
    "    split_renames= {})\n",
    "\n",
    "wthr['Datetime_Temp'] = wthr['Year']+'-'+wthr['Month']+'-'+wthr['Day']+' '+wthr['Time']\n",
    "\n",
    "# convert types\n",
    "err_list = find_unconvertable_datetimes(df_col=wthr['Datetime_Temp'], pattern='%Y-%m-%d %H:%M', index=False)\n",
    "if err_list != []:\n",
    "    print(err_list)\n",
    "else:\n",
    "    wthr.Datetime_Temp = pd.to_datetime(pd.Series(wthr.Datetime_Temp), errors='coerce')\n",
    "    wthr.Datetime = wthr.Datetime_Temp\n",
    "    wthr = wthr.drop(columns= 'Datetime_Temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e909cde2",
   "metadata": {},
   "source": [
    "### Simple Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed990b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to string\n",
    "wthr = cols_astype_string(\n",
    "    df = wthr, \n",
    "    col_list = [key for key in wthr_col_dtypes.keys() if wthr_col_dtypes[key] == 'string'])\n",
    "\n",
    "wthr.Year = year_string\n",
    "wthr.Year = wthr.Year.astype('string')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab20d1a",
   "metadata": {},
   "source": [
    "### Check Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53fd6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 Columns pass.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = check_df_dtype_expectations(df = wthr, dtype_dct = wthr_col_dtypes)\n",
    "\n",
    "if sum(checkpoint.Pass)/checkpoint.shape[0] == 1:\n",
    "    pass\n",
    "else:\n",
    "    print(checkpoint.loc[~checkpoint.Pass, ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1958033e",
   "metadata": {},
   "source": [
    "## Management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcf1a42",
   "metadata": {},
   "source": [
    "### Date_Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58adaa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgmt = relocate_to_Imputation_Notes(df = mgmt, col = 'Date_Datetime', val_list= ['fall 2019'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b612643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert types\n",
    "err_list = find_unconvertable_datetimes(df_col=mgmt.Date_Datetime, pattern='%m/%d/%y', index=False)\n",
    "if err_list != []:\n",
    "    print(err_list)\n",
    "else:\n",
    "    mgmt.Date_Datetime = pd.to_datetime(pd.Series(mgmt.Date_Datetime), format = '%m/%d/%y', errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497e0f42",
   "metadata": {},
   "source": [
    "### Amount_Per_Acre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaed882",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgmt = relocate_to_Imputation_Notes(df = mgmt, col = 'Amount_Per_Acre', val_list= ['variable rate according to soil sample'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef62795d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Experiment_Code</th>\n",
       "      <th>Range</th>\n",
       "      <th>Pass</th>\n",
       "      <th>Plot</th>\n",
       "      <th>Application</th>\n",
       "      <th>Product</th>\n",
       "      <th>Date_Datetime</th>\n",
       "      <th>Amount_Per_Acre</th>\n",
       "      <th>Unit</th>\n",
       "      <th>mgmt</th>\n",
       "      <th>Imputation_Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77802</th>\n",
       "      <td>2020</td>\n",
       "      <td>SCH1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Broadcast</td>\n",
       "      <td>BicepMagnum II</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>2 qts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77803</th>\n",
       "      <td>2020</td>\n",
       "      <td>SCH1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Broadcast</td>\n",
       "      <td>Glyphosate</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>2 qts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77804</th>\n",
       "      <td>2020</td>\n",
       "      <td>SCH1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Broadcast</td>\n",
       "      <td>Atrazine</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>2 qts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77805</th>\n",
       "      <td>2020</td>\n",
       "      <td>SCH1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Broadcast</td>\n",
       "      <td>BicepMagnum II</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>2 qts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77806</th>\n",
       "      <td>2020</td>\n",
       "      <td>SCH1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Broadcast</td>\n",
       "      <td>Glyphosate</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>2 qts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79711</th>\n",
       "      <td>2020</td>\n",
       "      <td>SCH1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>637</td>\n",
       "      <td>Broadcast</td>\n",
       "      <td>Glyphosate</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>2 qts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79712</th>\n",
       "      <td>2020</td>\n",
       "      <td>SCH1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>637</td>\n",
       "      <td>Broadcast</td>\n",
       "      <td>Atrazine</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>2 qts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79713</th>\n",
       "      <td>2020</td>\n",
       "      <td>SCH1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>638</td>\n",
       "      <td>Broadcast</td>\n",
       "      <td>BicepMagnum II</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>2 qts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79714</th>\n",
       "      <td>2020</td>\n",
       "      <td>SCH1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>638</td>\n",
       "      <td>Broadcast</td>\n",
       "      <td>Glyphosate</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>2 qts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79715</th>\n",
       "      <td>2020</td>\n",
       "      <td>SCH1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>638</td>\n",
       "      <td>Broadcast</td>\n",
       "      <td>Atrazine</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>2 qts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1914 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year Experiment_Code Range Pass Plot Application         Product  \\\n",
       "77802  2020            SCH1   1.0    1    1   Broadcast  BicepMagnum II   \n",
       "77803  2020            SCH1   1.0    1    1   Broadcast      Glyphosate   \n",
       "77804  2020            SCH1   1.0    1    1   Broadcast        Atrazine   \n",
       "77805  2020            SCH1   1.0    2    2   Broadcast  BicepMagnum II   \n",
       "77806  2020            SCH1   1.0    2    2   Broadcast      Glyphosate   \n",
       "...     ...             ...   ...  ...  ...         ...             ...   \n",
       "79711  2020            SCH1   8.0    2  637   Broadcast      Glyphosate   \n",
       "79712  2020            SCH1   8.0    2  637   Broadcast        Atrazine   \n",
       "79713  2020            SCH1   8.0    1  638   Broadcast  BicepMagnum II   \n",
       "79714  2020            SCH1   8.0    1  638   Broadcast      Glyphosate   \n",
       "79715  2020            SCH1   8.0    1  638   Broadcast        Atrazine   \n",
       "\n",
       "      Date_Datetime Amount_Per_Acre Unit  mgmt Imputation_Notes  \n",
       "77802    2020-05-12           2 qts  NaN  True              NaN  \n",
       "77803    2020-05-12           2 qts  NaN  True              NaN  \n",
       "77804    2020-06-10           2 qts  NaN  True              NaN  \n",
       "77805    2020-05-12           2 qts  NaN  True              NaN  \n",
       "77806    2020-05-12           2 qts  NaN  True              NaN  \n",
       "...             ...             ...  ...   ...              ...  \n",
       "79711    2020-05-12           2 qts  NaN  True              NaN  \n",
       "79712    2020-06-10           2 qts  NaN  True              NaN  \n",
       "79713    2020-05-12           2 qts  NaN  True              NaN  \n",
       "79714    2020-05-12           2 qts  NaN  True              NaN  \n",
       "79715    2020-06-10           2 qts  NaN  True              NaN  \n",
       "\n",
       "[1914 rows x 12 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mgmt.loc[find_unconvertable_numerics(df_col = mgmt['Amount_Per_Acre'], index = True), ]\n",
    "\n",
    "mgmt.loc[mgmt.Amount_Per_Acre == '2 qts', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a222c8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (mgmt.Amount_Per_Acre == '2 qts')\n",
    "mgmt.loc[mask, 'Unit'] = 'qts'\n",
    "mgmt.loc[mask, 'Amount_Per_Acre'] = '2'\n",
    "\n",
    "mask = (mgmt.Amount_Per_Acre == '1.5 qts')\n",
    "mgmt.loc[mask, 'Unit'] = 'qts'\n",
    "mgmt.loc[mask, 'Amount_Per_Acre'] = '1.5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc11303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert types\n",
    "err_list = find_unconvertable_numerics(df_col = mgmt['Amount_Per_Acre'], index = False)\n",
    "if err_list != []:\n",
    "    print(err_list)\n",
    "else:\n",
    "    mgmt.Amount_Per_Acre = pd.to_numeric(mgmt.Amount_Per_Acre, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829c3e99",
   "metadata": {},
   "source": [
    "### Simple Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb60d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to bool\n",
    "mgmt['mgmt'] = mgmt['mgmt'].astype('bool')\n",
    "\n",
    "# to string\n",
    "for e in [ee for ee in ['Application', 'Product', 'Ingredient', 'Unit', 'Imputation_Notes'] if ee in mgmt.columns]:\n",
    "    mgmt[e] = mgmt[e].astype('string')\n",
    "    \n",
    "\n",
    "mgmt.Year = year_string\n",
    "mgmt.Year = mgmt.Year.astype('string')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b2160e",
   "metadata": {},
   "source": [
    "### Check Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1578ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 Columns pass.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>Expected_dtype</th>\n",
       "      <th>Pass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Year</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Experiment_Code</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Range</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pass</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plot</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Application</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Product</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Date_Datetime</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Amount_Per_Acre</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Unit</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mgmt</td>\n",
       "      <td>bool</td>\n",
       "      <td>bool</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Imputation_Notes</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Column           dtype  Expected_dtype  Pass\n",
       "0               Year          string          string  True\n",
       "1    Experiment_Code          string          string  True\n",
       "2              Range          string          string  True\n",
       "3               Pass          string          string  True\n",
       "4               Plot          string          string  True\n",
       "5        Application          string          string  True\n",
       "6            Product          string          string  True\n",
       "7      Date_Datetime  datetime64[ns]  datetime64[ns]  True\n",
       "8    Amount_Per_Acre         float64         float64  True\n",
       "9               Unit          string          string  True\n",
       "10              mgmt            bool            bool  True\n",
       "11  Imputation_Notes          string          string  True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_df_dtype_expectations(df = mgmt, dtype_dct = mgmt_col_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3109ee8b",
   "metadata": {},
   "source": [
    "# Publish\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf01fde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_out_pkl(obj = sval, path = './data/interim/'+year_string+'sval.pickle')\n",
    "write_out_pkl(obj = wthr, path = './data/interim/'+year_string+'wthr.pickle')\n",
    "write_out_pkl(obj = mgmt, path = './data/interim/'+year_string+'mgmt.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
