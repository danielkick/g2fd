{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce112a12",
   "metadata": {},
   "source": [
    "# Process Data from 2017 into a consistent format.\n",
    "\n",
    "> This notebook brings the 2017 into alignment with the desired format with respect to field name, type, and grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9bf5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports ----\n",
    "import re\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf3e182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from g2fd.internal import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569c88f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp internal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1692f5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2017\n",
    "year_string = '2017'\n",
    "\n",
    "meta_path = './data/raw/G2F_Planting_Season_2017_v1/z._2017_supplemental_info/g2f_2017_field_metadata.csv' \n",
    "phno_path = './data/raw/G2F_Planting_Season_2017_v1/a._2017_hybrid_phenotypic_data/g2f_2017_hybrid_data_clean.csv' # geno_path = None,  \n",
    "wthr_path = './data/raw/G2F_Planting_Season_2017_v1/b._2017_weather_data/g2f_2017_weather_data.csv'\n",
    "soil_path = './data/raw/G2F_Planting_Season_2017_v1/c._2017_soil_data/g2f_2017_soil_data_clean.csv'\n",
    "mgmt_path = './data/raw/G2F_Planting_Season_2017_v1/z._2017_supplemental_info/g2f_2017_agronomic information.csv'\n",
    "\n",
    "meta = pd.read_csv(meta_path, encoding = \"ISO-8859-1\", low_memory=False)\n",
    "phno = pd.read_csv(phno_path, encoding = \"ISO-8859-1\", low_memory=False)\n",
    "wthr = pd.read_csv(wthr_path, encoding = \"ISO-8859-1\", low_memory=False)\n",
    "soil = pd.read_csv(soil_path, encoding = \"ISO-8859-1\", low_memory=False)\n",
    "mgmt = pd.read_csv(mgmt_path, encoding = \"ISO-8859-1\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d31cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dicts for column renaming\n",
    "meta_name_dict = mk_name_dict(name = 'meta')\n",
    "phno_name_dict = mk_name_dict(name = 'phno')\n",
    "soil_name_dict = mk_name_dict(name = 'soil')\n",
    "wthr_name_dict = mk_name_dict(name = 'wthr')\n",
    "mgmt_name_dict = mk_name_dict(name = 'mgmt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1ab577",
   "metadata": {},
   "source": [
    "# Rename\n",
    "**Naming rules:**\n",
    "- One dict for each input df\n",
    "- Comment out anything that shouldn't be changed\n",
    "- Upper_Upper_Unit_\\$unit\n",
    "- Upper_$number\n",
    "- No special characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0b0a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [], [], [], [])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(find_unrecognized_columns(df = meta, dct = meta_name_dict),\n",
    "find_unrecognized_columns(df = phno, dct = phno_name_dict),\n",
    "find_unrecognized_columns(df = soil, dct = soil_name_dict),\n",
    "find_unrecognized_columns(df = wthr, dct = wthr_name_dict),\n",
    "find_unrecognized_columns(df = mgmt, dct = mgmt_name_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9080f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = meta.rename(columns=meta_name_dict)\n",
    "phno = phno.rename(columns=phno_name_dict)\n",
    "soil = soil.rename(columns=soil_name_dict)\n",
    "wthr = wthr.rename(columns=wthr_name_dict)\n",
    "mgmt = mgmt.rename(columns=mgmt_name_dict)\n",
    "\n",
    "# add indicator columns to help with debugging merge\n",
    "meta['meta'] = True\n",
    "phno['phno'] = True\n",
    "soil['soil'] = True\n",
    "wthr['wthr'] = True\n",
    "mgmt['mgmt'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485b4fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32, 55), (18381, 39), (28, 28), (253994, 27), (123, 7)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e.shape for e in [meta, phno, soil, wthr, mgmt]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1589ac0",
   "metadata": {},
   "source": [
    "# Sanatize ID columns as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca242c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "soil = sanitize_Experiment_Codes(\n",
    "    df = soil, \n",
    "    simple_renames = {\n",
    "        'NEH3 (IRRIGATED)': 'NEH3', \n",
    "        'NEH4 (NON IRRIGATED)': 'NEH4'\n",
    "    }, \n",
    "    split_renames = {\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864c852a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta [] \n",
      "phno [] \n",
      "soil [] \n",
      "wthr [] \n",
      "mgmt [] \n",
      "all  ['ARH1', 'ARH2', 'COH1', 'DEH1', 'GAH1', 'GAH2', 'GEH1', 'GEH2', 'IAH1', 'IAH2', 'IAH2 ', 'IAH3', 'IAH3 ', 'IAH4', 'IAH4 ', 'ILH1', 'ILH2', 'INH1', 'KSH1', 'KSH2', 'KSH3', 'MIH1', 'MNH1', 'MOH1', 'MOH1 ', 'MOH1-Rep1', 'MOH1-Rep2', 'NCH1', 'NEH1', 'NEH2', 'NEH3', 'NEH4', 'NYH1', 'NYH1', 'NYH2', 'NYH3', 'NYH4', 'NYS1', 'OHH1', 'ONH1', 'ONH2', 'SCH1', 'TXH1', 'TXH1-Dry', 'TXH1-Early', 'TXH1-Late', 'TXH2', 'TXH3', 'TXH4', 'W1H1', 'W1H2', 'WIH1', 'WIH2', 'WIH3']\n"
     ]
    }
   ],
   "source": [
    "# confirm everything's okay\n",
    "print(\n",
    "  'meta', find_unrecognized_experiments(meta.Experiment_Code, return_all_exps=False), \n",
    "'\\nphno', find_unrecognized_experiments(phno.Experiment_Code, return_all_exps=False),\n",
    "'\\nsoil', find_unrecognized_experiments(soil.Experiment_Code, return_all_exps=False),\n",
    "'\\nwthr', find_unrecognized_experiments(wthr.Experiment_Code, return_all_exps=False),\n",
    "'\\nmgmt', find_unrecognized_experiments(mgmt.Experiment_Code, return_all_exps=False),\n",
    "'\\nall ', find_unrecognized_experiments([], return_all_exps=True)\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eaedb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7961f93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block and Replicate are equivalent\n",
    "phno = phno.drop(columns = ['Block', 'Drop_Record_Index'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c37165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Additional_ID</th>\n",
       "      <th>Uniq_Vals</th>\n",
       "      <th>At_Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Experiment_Code</td>\n",
       "      <td>18381</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Source</td>\n",
       "      <td>18381</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pedigree</td>\n",
       "      <td>18381</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Local_Check</td>\n",
       "      <td>18381</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Additional_ID  Uniq_Vals  At_Target\n",
       "0  Experiment_Code      18381       True\n",
       "1           Source      18381       True\n",
       "2         Pedigree      18381       True\n",
       "3      Local_Check      18381       True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find minimum cols needed to index all rows\n",
    "df = phno\n",
    "id_cols = ['Year', 'Experiment_Code', 'Range', 'Pass', 'Plot','Replicate']\n",
    "candidate_cols = ['Experiment_Code', 'Source', 'Pedigree', 'Local_Check']\n",
    "target = df.shape[0]\n",
    "\n",
    "output = pd.DataFrame(zip(\n",
    "    candidate_cols,\n",
    "    [df.loc[:, id_cols+[e]].drop_duplicates().shape[0] for e in candidate_cols]\n",
    "   ), columns=['Additional_ID', 'Uniq_Vals'])\n",
    "\n",
    "output.assign(At_Target=lambda x:x.Uniq_Vals == target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94761eb",
   "metadata": {},
   "source": [
    "# Rearrange columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87974ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # separate static and dynamic values\n",
    "sval = phno.merge(soil, how = 'outer')\n",
    "sval = sval.merge(meta, how = 'outer')\n",
    "\n",
    "\n",
    "# these tables are different enought we'll keep them separate\n",
    "# mgmt\n",
    "# unfortunately we need multiples because at least one field treats different passes differently\n",
    "mgmt = phno.loc[:, ['Year', 'Experiment_Code', 'Range', 'Pass', 'Plot', 'phno']\n",
    "               ].drop_duplicates().merge(mgmt, how = 'outer')\n",
    "mgmt = mgmt.drop(columns='phno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4090cb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set each id col to a string\n",
    "for i in ['Year', 'Experiment_Code', 'Range', 'Pass', 'Plot']:\n",
    "    sval[i] = sval[i].astype('string')\n",
    "    mgmt[i]  =  mgmt[i].astype('string')\n",
    "    \n",
    "    if i not in ['Range', 'Pass', 'Plot']:\n",
    "        wthr[i]  =  wthr[i].astype('string')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a94f13",
   "metadata": {},
   "source": [
    "# Sanitize Non-ID columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcc8720",
   "metadata": {},
   "source": [
    "## Sanitization functions\n",
    "\n",
    "The pattern to use is:\n",
    " 1. Alter the dataframe\n",
    " 1. Test the dataframe against expectations\n",
    " \n",
    "The main tasks that need to be completed are:\n",
    " 1. Identify values that can't be converted to the expected data type. The \"find_unconvertable_\" family of functions should be used. \n",
    "     1. `find_unconvertable_datetimes`\n",
    "     \n",
    " 1. For simple renaming (e.g. misspellings) or splitting non-tidy data into two rows (\"entry1-entry2\" -> \"entry1\", \"entry2\") use `sanitize_col` \n",
    " 1. Move values that are ambigous but pertain to data imputation to \"Imputation_Notes\" using `relocate_to_Imputation_Notes`\n",
    " 1. If new columns need to be added (e.g. mgmt.Ingredient for parsed components of Product (e.g. elements) ) this should be accomplished with `safe_create_col`.\n",
    " 1. Any one off changes should be accomplised manually. \n",
    " 1. Confirm columns match the expected types with `check_df_dtype_expectations`, and report mismatches. \n",
    "\n",
    "\n",
    "These steps should be completed for each dataframe in turn to minimize the cognitive load of the reader. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cad031",
   "metadata": {},
   "source": [
    "## Sanitization: Column data type expectations\n",
    "Note: to handle missing values some columns that would otherwise be ints are floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40b6f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "sval_col_dtypes = mk_dtype_dict(name = 'sval')\n",
    "wthr_col_dtypes = mk_dtype_dict(name = 'wthr')\n",
    "mgmt_col_dtypes = mk_dtype_dict(name = 'mgmt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972cfb9f",
   "metadata": {},
   "source": [
    "# Sanitization: Alter entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccee17b",
   "metadata": {},
   "source": [
    "## Static values (within season)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ab9954",
   "metadata": {},
   "source": [
    "### Datetime containing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d2d163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the date cols into datetime. Lean on pd.to_datetime() to infer the format, assume that each site uses the same format.\n",
    "\n",
    "for e in ['Planted_Unit_Datetime', \n",
    "    'Harvested_Unit_Datetime', \n",
    "    'Anthesis_Unit_Datetime', \n",
    "    'Silking_Unit_Datetime', \n",
    "    'Recieved_Date_Unit_Datetime', \n",
    "    'Processed_Date_Unit_Datetime', \n",
    "    'Weather_Station_Placed_Unit_Datetime', \n",
    "    'Weather_Station_Removed_Unit_Datetime'\n",
    "    ]:\n",
    "# find_unconvertable_datetimes(df_col=sval[e], pattern='%Y-%m-%d %H:%M', index=False)\n",
    "\n",
    "    sval['Datetime_Temp'] = pd.to_datetime(np.nan)\n",
    "\n",
    "    for code in list(sval.Experiment_Code.drop_duplicates()):\n",
    "    # code = list(sval.Experiment_Code.drop_duplicates())[0]\n",
    "        sval.loc[sval.Experiment_Code == code, 'Datetime_Temp'\n",
    "                 ] = pd.to_datetime(sval.loc[sval.Experiment_Code == code, e])\n",
    "\n",
    "    sval.loc[:, e] = sval.loc[:, 'Datetime_Temp'] \n",
    "\n",
    "sval = sval.drop(columns = 'Datetime_Temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826b9321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to bool\n",
    "sval = sanitize_col(\n",
    "    df = sval, \n",
    "    col = 'Discarded', \n",
    "    simple_renames= {\n",
    "        'Yes':'True',\n",
    "        'yes':'True'}, \n",
    "    split_renames= {})\n",
    "\n",
    "# set missing to false\n",
    "sval.loc[sval.Discarded.isna(), 'Discarded'] = 'False'\n",
    "sval.Discarded = sval.Discarded.map({'True': True, 'False': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e4df11",
   "metadata": {},
   "source": [
    "### Simple Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6927f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to float\n",
    "sval = sanitize_col(\n",
    "    df = sval, \n",
    "    col = 'Pounds_Needed_Soil_Moisture', \n",
    "    simple_renames= {\n",
    "        \"Based on the technitian's experience a minimum of 4 lbs is required. However the user manual says the minimum volume for accurate determination is 2 liters\":'4',\n",
    "        '5-6.5':'5.25'}, \n",
    "    split_renames= {})\n",
    "\n",
    "sval.Pounds_Needed_Soil_Moisture = sval.Pounds_Needed_Soil_Moisture.astype(float)\n",
    "# find_unconvertable_numerics(sval.Pounds_Needed_Soil_Moisture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4d9b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddff036",
   "metadata": {},
   "outputs": [],
   "source": [
    "sval = sval.drop(columns=['Additional_Metics']) # no non null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9768e7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to bool\n",
    "sval['phno'] = sval['phno'].astype('bool')\n",
    "sval['soil'] = sval['soil'].astype('bool')\n",
    "sval['meta'] = sval['meta'].astype('bool')\n",
    "\n",
    "# # to string\n",
    "sval = cols_astype_string(\n",
    "    df = sval, \n",
    "    col_list = [key for key in sval_col_dtypes.keys() if sval_col_dtypes[key] == 'string'])\n",
    "\n",
    "# sval.Year = year_string\n",
    "# sval.Year = sval.Year.astype('string')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55b1261",
   "metadata": {},
   "source": [
    "### Check Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec742610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 Columns pass.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = check_df_dtype_expectations(df = sval, dtype_dct = sval_col_dtypes)\n",
    "\n",
    "if sum(checkpoint.Pass)/checkpoint.shape[0] == 1:\n",
    "    pass\n",
    "else:\n",
    "    print(checkpoint.loc[~checkpoint.Pass, ]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54014602",
   "metadata": {},
   "source": [
    "## Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af31085f",
   "metadata": {},
   "source": [
    "### Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014fffaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of writing regexes to figure out the mose likely format for each datetime, we assume each experiment will be consistent withing that experiment\n",
    "# and let pd figure it out.\n",
    "wthr['Datetime_Temp'] = pd.to_datetime(np.nan)\n",
    "wthr['Datetime'] = pd.to_datetime(np.nan) # no Datetime col \n",
    "\n",
    "wthr['Datetime_Temp'] = wthr['Year'].astype('string')+'-'+wthr['Month'].astype('string')+'-'+wthr['Day'].astype('string')+' '+wthr['Time'].astype('string')\n",
    "wthr['Datetime'] = pd.to_datetime(wthr['Datetime_Temp'])\n",
    "wthr = wthr.drop(columns= 'Datetime_Temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e61b079",
   "metadata": {},
   "source": [
    "### Data_Cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6ac4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to bool\n",
    "wthr = sanitize_col(\n",
    "    df = wthr, \n",
    "    col = 'Data_Cleaned', \n",
    "    simple_renames= {\n",
    "        'Yes':'True',\n",
    "        'No':'False'}, \n",
    "    split_renames= {})\n",
    "\n",
    "# set missing to false\n",
    "wthr.loc[wthr.Data_Cleaned.isna(), 'Data_Cleaned'] = 'False'\n",
    "wthr.Data_Cleaned = wthr.Data_Cleaned.map({'True': True, 'False': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ccd74b",
   "metadata": {},
   "source": [
    "### Simple Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed990b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to string\n",
    "wthr = cols_astype_string(\n",
    "    df = wthr, \n",
    "    col_list = [key for key in wthr_col_dtypes.keys() if wthr_col_dtypes[key] == 'string'])\n",
    "\n",
    "wthr.Year = year_string\n",
    "wthr.Year = wthr.Year.astype('string')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801ad550",
   "metadata": {},
   "source": [
    "### Check Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53fd6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 Columns pass.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = check_df_dtype_expectations(df = wthr, dtype_dct = wthr_col_dtypes)\n",
    "\n",
    "if sum(checkpoint.Pass)/checkpoint.shape[0] == 1:\n",
    "    pass\n",
    "else:\n",
    "    print(checkpoint.loc[~checkpoint.Pass, ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1958033e",
   "metadata": {},
   "source": [
    "## Management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcf1a42",
   "metadata": {},
   "source": [
    "### Date_Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e9cd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgmt = sanitize_col(\n",
    "    df = mgmt, \n",
    "    col = 'Date_Datetime', \n",
    "    simple_renames= {\n",
    "        '13-Apr':'Thursday, April 13, 2017',\n",
    "        '4/28/17':'Friday, April 28, 2017',\n",
    "        '5/23/17':'Tuesday, May 23, 2017'}, \n",
    "    split_renames= {})\n",
    "\n",
    "mgmt['Date_Datetime'] = pd.to_datetime(mgmt['Date_Datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2732160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert types\n",
    "err_list = find_unconvertable_datetimes(df_col=mgmt.Date_Datetime, pattern='%m/%d/%y', index=False)\n",
    "if err_list != []:\n",
    "    print(err_list)\n",
    "else:\n",
    "    mgmt.Date_Datetime = pd.to_datetime(pd.Series(mgmt.Date_Datetime), format = '%m/%d/%y', errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497e0f42",
   "metadata": {},
   "source": [
    "### Amount_Per_Acre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b5f0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (mgmt.Amount_Per_Acre == '375 lbs./A')\n",
    "mgmt.loc[mask, ['Amount_Per_Acre', 'Unit'] ] = ['375', 'lbs']\n",
    "\n",
    "mask = (mgmt.Amount_Per_Acre == '2 lbs./A')\n",
    "mgmt.loc[mask, ['Amount_Per_Acre', 'Unit'] ] = ['2', 'lbs']\n",
    "\n",
    "mask = (mgmt.Amount_Per_Acre == 'all rates per acre')\n",
    "mgmt.loc[mask, 'Amount_Per_Acre' ] = np.nan \n",
    "\n",
    "mask = (mgmt.Amount_Per_Acre == '260 lb/ac')\n",
    "mgmt.loc[mask, ['Amount_Per_Acre', 'Unit'] ] = ['260', 'lbs']\n",
    "\n",
    "mask = (mgmt.Amount_Per_Acre == '6.5 lbs./A')\n",
    "mgmt.loc[mask, ['Amount_Per_Acre', 'Unit'] ] = ['6.5', 'lbs']\n",
    "\n",
    "mask = (mgmt.Amount_Per_Acre == '42 GPA')\n",
    "mgmt.loc[mask, ['Amount_Per_Acre', 'Unit'] ] = ['42', 'GPA']\n",
    "\n",
    "mask = (mgmt.Amount_Per_Acre == '1 qt./A')\n",
    "mgmt.loc[mask, ['Amount_Per_Acre', 'Unit'] ] = ['1', 'qt']\n",
    "\n",
    "mask = (mgmt.Amount_Per_Acre == '1.5 qt./A')\n",
    "mgmt.loc[mask, ['Amount_Per_Acre', 'Unit'] ] = ['1.5', 'qt']\n",
    "\n",
    "mask = (mgmt.Amount_Per_Acre == '1 oz./A')\n",
    "mgmt.loc[mask, ['Amount_Per_Acre', 'Unit'] ] = ['1', 'oz']\n",
    "\n",
    "mask = (mgmt.Amount_Per_Acre == '110 lbs./N')\n",
    "mgmt.loc[mask, ['Amount_Per_Acre', 'Unit'] ] = ['100', 'lbs']\n",
    "\n",
    "mask = (mgmt.Amount_Per_Acre == '1.5 pt./A')\n",
    "mgmt.loc[mask, ['Amount_Per_Acre', 'Unit'] ] = ['1.5', 'pt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d4701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgmt = sanitize_col(\n",
    "    df = mgmt, \n",
    "    col = 'Amount_Per_Acre', \n",
    "    simple_renames= {'NPK 0-0-51': '51 (K)', \n",
    "                    '100 units per acre': '100', \n",
    "                    '80 units per acre': '80'}, \n",
    "    split_renames= {'NPK 14-65-0': ['14 (N)', '65 (P)'], \n",
    "                    '27N, 26P': ['27 (N)', '26 (P)']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ead32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgmt = safe_create_col(mgmt, \"Ingredient\")\n",
    "mask = mgmt.Ingredient.isna()\n",
    "mgmt.loc[mask, 'Ingredient'] = mgmt.loc[mask, 'Product']\n",
    "\n",
    "# assume each string is formated as 'val (key)'. `sanitize_col` should be used to enforce this.\n",
    "for e in ['26 (P)', '27 (N)', '14 (N)', '65 (P)', '51 (K)']:\n",
    "    val = re.findall('^\\d+[.]*\\d*', e)[0]\n",
    "    key = re.findall('\\(.+\\)',      e)[0].replace('(', '').replace(')', '')\n",
    "    \n",
    "    mask = (mgmt['Amount_Per_Acre'] == e)\n",
    "    mgmt.loc[mask, 'Ingredient'] = key\n",
    "    mgmt.loc[mask, 'Amount_Per_Acre'] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc11303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert types\n",
    "err_list = find_unconvertable_numerics(df_col = mgmt['Amount_Per_Acre'], index = False)\n",
    "if err_list != []:\n",
    "    print(err_list)\n",
    "else:\n",
    "    mgmt.Amount_Per_Acre = pd.to_numeric(mgmt.Amount_Per_Acre, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57973e80",
   "metadata": {},
   "source": [
    "### Ingredient\n",
    "This is to be the cleaned up version of the \"Product\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66140777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(mgmt.loc[:, 'Ingredient'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829c3e99",
   "metadata": {},
   "source": [
    "### Simple Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb60d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to bool\n",
    "mgmt['mgmt'] = mgmt['mgmt'].astype('bool')\n",
    "\n",
    "# to string\n",
    "for e in [ee for ee in ['Application', 'Product', 'Ingredient', 'Unit', 'Imputation_Notes'] if ee in mgmt.columns]:\n",
    "    mgmt[e] = mgmt[e].astype('string')\n",
    "    \n",
    "\n",
    "mgmt.Year = year_string\n",
    "mgmt.Year = mgmt.Year.astype('string')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b2160e",
   "metadata": {},
   "source": [
    "### Check Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1578ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 Columns pass.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>Expected_dtype</th>\n",
       "      <th>Pass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Year</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Experiment_Code</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Range</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pass</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plot</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Application</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Product</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Date_Datetime</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Amount_Per_Acre</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Unit</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mgmt</td>\n",
       "      <td>bool</td>\n",
       "      <td>bool</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ingredient</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Column           dtype  Expected_dtype  Pass\n",
       "0              Year          string          string  True\n",
       "1   Experiment_Code          string          string  True\n",
       "2             Range          string          string  True\n",
       "3              Pass          string          string  True\n",
       "4              Plot          string          string  True\n",
       "5       Application          string          string  True\n",
       "6           Product          string          string  True\n",
       "7     Date_Datetime  datetime64[ns]  datetime64[ns]  True\n",
       "8   Amount_Per_Acre         float64         float64  True\n",
       "9              Unit          string          string  True\n",
       "10             mgmt            bool            bool  True\n",
       "11       Ingredient          string          string  True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_df_dtype_expectations(df = mgmt, dtype_dct = mgmt_col_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3109ee8b",
   "metadata": {},
   "source": [
    "# Publish\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf01fde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_out_pkl(obj = sval, path = './data/interim/'+year_string+'sval.pickle')\n",
    "write_out_pkl(obj = wthr, path = './data/interim/'+year_string+'wthr.pickle')\n",
    "write_out_pkl(obj = mgmt, path = './data/interim/'+year_string+'mgmt.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
